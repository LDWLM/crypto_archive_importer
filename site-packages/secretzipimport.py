# -----------------------------------------------------zipfileaes-----------------------------------------------------
import struct

# from Cryptodome.Protocol.KDF import PBKDF2
# from Cryptodome.Cipher import AES
# from Cryptodome.Hash import HMAC
# from Cryptodome.Hash.SHA1 import SHA1Hash
# from Cryptodome.Util import Counter
# from Cryptodome import Random

"""
Read and write ZIP files.

XXX references to utf-8 need further investigation.
"""
import io
import os
import importlib.util
import logging
import sys
import time
import stat
import shutil
import struct
import binascii
import threading

if sys.version_info[0:2] < (3, 6):
    import pathlib

try:
    import zlib  # We may need its compression method
    crc32 = zlib.crc32
except ImportError:
    zlib = None
    crc32 = binascii.crc32

try:
    import bz2  # We may need its compression method
except ImportError:
    bz2 = None

try:
    import lzma  # We may need its compression method
except ImportError:
    lzma = None

# __all__ = ["BadZipFile", "BadZipfile", "error",
#            "ZIP_STORED", "ZIP_DEFLATED", "ZIP_BZIP2", "ZIP_LZMA",
#            "is_zipfile", "ZipInfo", "ZipFile", "PyZipFile", "LargeZipFile"]


class BadZipFile(Exception):
    pass


class LargeZipFile(Exception):
    """
    Raised when writing a zipfile, the zipfile requires ZIP64 extensions
    and those extensions are disabled.
    """


error = BadZipfile = BadZipFile      # Pre-3.2 compatibility names


ZIP64_LIMIT = (1 << 31) - 1
ZIP_FILECOUNT_LIMIT = (1 << 16) - 1
ZIP_MAX_COMMENT = (1 << 16) - 1

# constants for Zip file compression methods
ZIP_STORED = 0
ZIP_DEFLATED = 8
ZIP_BZIP2 = 12
ZIP_LZMA = 14
# Other ZIP compression methods not supported

DEFAULT_VERSION = 20
ZIP64_VERSION = 45
BZIP2_VERSION = 46
LZMA_VERSION = 63
# we recognize (but not necessarily support) all features up to that version
MAX_EXTRACT_VERSION = 63

# Extensible data field codes:
# Zip64 extended information extra field
EXTRA_ZIP64 = 0x0001

# Below are some formats and associated data for reading/writing headers using
# the struct module.  The names and structures of headers/records are those used
# in the PKWARE description of the ZIP file format:
#     http://www.pkware.com/documents/casestudies/APPNOTE.TXT
# (URL valid as of January 2008)

# The "end of central directory" structure, magic number, size, and indices
# (section V.I in the format document)
structEndArchive = b"<4s4H2LH"
stringEndArchive = b"PK\005\006"
sizeEndCentDir = struct.calcsize(structEndArchive)

_ECD_SIGNATURE = 0
_ECD_DISK_NUMBER = 1
_ECD_DISK_START = 2
_ECD_ENTRIES_THIS_DISK = 3
_ECD_ENTRIES_TOTAL = 4
_ECD_SIZE = 5
_ECD_OFFSET = 6
_ECD_COMMENT_SIZE = 7
# These last two indices are not part of the structure as defined in the
# spec, but they are used internally by this module as a convenience
_ECD_COMMENT = 8
_ECD_LOCATION = 9

# The "central directory" structure, magic number, size, and indices
# of entries in the structure (section V.F in the format document)
structCentralDir = "<4s4B4HL2L5H2L"
stringCentralDir = b"PK\001\002"
sizeCentralDir = struct.calcsize(structCentralDir)

# indexes of entries in the central directory structure
_CD_SIGNATURE = 0
_CD_CREATE_VERSION = 1
_CD_CREATE_SYSTEM = 2
_CD_EXTRACT_VERSION = 3
_CD_EXTRACT_SYSTEM = 4
_CD_FLAG_BITS = 5
_CD_COMPRESS_TYPE = 6
_CD_TIME = 7
_CD_DATE = 8
_CD_CRC = 9
_CD_COMPRESSED_SIZE = 10
_CD_UNCOMPRESSED_SIZE = 11
_CD_FILENAME_LENGTH = 12
_CD_EXTRA_FIELD_LENGTH = 13
_CD_COMMENT_LENGTH = 14
_CD_DISK_NUMBER_START = 15
_CD_INTERNAL_FILE_ATTRIBUTES = 16
_CD_EXTERNAL_FILE_ATTRIBUTES = 17
_CD_LOCAL_HEADER_OFFSET = 18

_MASK_ENCRYPTED = 1 << 0
_MASK_COMPRESS_OPTION_1 = 1 << 1
_MASK_COMPRESS_OPTION_2 = 1 << 2
_MASK_USE_DATA_DESCRIPTOR = 1 << 3
# Bit 4: Reserved for use with compression method 8, for enhanced deflating.
_MASK_RESERVED_BIT_4 = 1 << 4
_MASK_COMPRESSED_PATCH = 1 << 5
_MASK_STRONG_ENCRYPTION = 1 << 6
_MASK_UNUSED_BIT_7 = 1 << 7
_MASK_UNUSED_BIT_8 = 1 << 8
_MASK_UNUSED_BIT_9 = 1 << 9
_MASK_UNUSED_BIT_10 = 1 << 10
_MASK_UTF_FILENAME = 1 << 11
# Bit 12: Reserved by PKWARE for enhanced compression.
_MASK_RESERVED_BIT_12 = 1 << 12
_MASK_ENCRYPTED_CENTRAL_DIR = 1 << 13
# Bit 14, 15: Reserved by PKWARE
_MASK_RESERVED_BIT_14 = 1 << 14
_MASK_RESERVED_BIT_15 = 1 << 15

# The "local file header" structure, magic number, size, and indices
# (section V.A in the format document)
structFileHeader = "<4s2B4HL2L2H"
stringFileHeader = b"PK\003\004"
sizeFileHeader = struct.calcsize(structFileHeader)

_FH_SIGNATURE = 0
_FH_EXTRACT_VERSION = 1
_FH_EXTRACT_SYSTEM = 2
_FH_GENERAL_PURPOSE_FLAG_BITS = 3
_FH_COMPRESSION_METHOD = 4
_FH_LAST_MOD_TIME = 5
_FH_LAST_MOD_DATE = 6
_FH_CRC = 7
_FH_COMPRESSED_SIZE = 8
_FH_UNCOMPRESSED_SIZE = 9
_FH_FILENAME_LENGTH = 10
_FH_EXTRA_FIELD_LENGTH = 11

# The "Zip64 end of central directory locator" structure, magic number, and size
structEndArchive64Locator = "<4sLQL"
stringEndArchive64Locator = b"PK\x06\x07"
sizeEndCentDir64Locator = struct.calcsize(structEndArchive64Locator)

# The "Zip64 end of central directory" record, magic number, size, and indices
# (section V.G in the format document)
structEndArchive64 = "<4sQ2H2L4Q"
stringEndArchive64 = b"PK\x06\x06"
sizeEndCentDir64 = struct.calcsize(structEndArchive64)

_CD64_SIGNATURE = 0
_CD64_DIRECTORY_RECSIZE = 1
_CD64_CREATE_VERSION = 2
_CD64_EXTRACT_VERSION = 3
_CD64_DISK_NUMBER = 4
_CD64_DISK_NUMBER_START = 5
_CD64_NUMBER_ENTRIES_THIS_DISK = 6
_CD64_NUMBER_ENTRIES_TOTAL = 7
_CD64_DIRECTORY_SIZE = 8
_CD64_OFFSET_START_CENTDIR = 9

_DD_SIGNATURE = 0x08074b50

_EXTRA_FIELD_STRUCT = struct.Struct('<HH')

def _strip_extra(extra, xids):
    # Remove Extra Fields with specified IDs.
    unpack = _EXTRA_FIELD_STRUCT.unpack
    modified = False
    buffer = []
    start = i = 0
    while i + 4 <= len(extra):
        xid, xlen = unpack(extra[i: i + 4])
        j = i + 4 + xlen
        if xid in xids:
            if i != start:
                buffer.append(extra[start: i])
            start = j
            modified = True
        i = j
    if not modified:
        return extra
    return b''.join(buffer)


def _check_zipfile(fp):
    try:
        if _EndRecData(fp):
            return True         # file has correct magic number
    except OSError:
        pass
    return False


def is_zipfile(filename):
    """Quickly see if a file is a ZIP file by checking the magic number.

    The filename argument may be a file or file-like object too.
    """
    result = False
    try:
        if hasattr(filename, "read"):
            result = _check_zipfile(fp=filename)
        else:
            # compat with Path objects were added in python 3.6
            if sys.version_info[0:2] < (3, 6):
                filename = str(filename)
            with open(filename, "rb") as fp:
                result = _check_zipfile(fp)
    except OSError:
        pass
    return result


def _EndRecData64(fpin, offset, endrec):
    """
    Read the ZIP64 end-of-archive records and use that to update endrec
    """
    try:
        fpin.seek(offset - sizeEndCentDir64Locator, 2)
    except OSError:
        # If the seek fails, the file is not large enough to contain a ZIP64
        # end-of-archive record, so just return the end record we were given.
        return endrec

    data = fpin.read(sizeEndCentDir64Locator)
    if len(data) != sizeEndCentDir64Locator:
        return endrec
    sig, diskno, reloff, disks = struct.unpack(structEndArchive64Locator, data)
    if sig != stringEndArchive64Locator:
        return endrec

    if diskno != 0 or disks != 1:
        raise BadZipFile("zipfiles that span multiple disks are not supported")

    # Assume no 'zip64 extensible data'
    fpin.seek(offset - sizeEndCentDir64Locator - sizeEndCentDir64, 2)
    data = fpin.read(sizeEndCentDir64)
    if len(data) != sizeEndCentDir64:
        return endrec
    sig, sz, create_version, read_version, disk_num, disk_dir, \
        dircount, dircount2, dirsize, diroffset = \
        struct.unpack(structEndArchive64, data)
    if sig != stringEndArchive64:
        return endrec

    # Update the original endrec using data from the ZIP64 record
    endrec[_ECD_SIGNATURE] = sig
    endrec[_ECD_DISK_NUMBER] = disk_num
    endrec[_ECD_DISK_START] = disk_dir
    endrec[_ECD_ENTRIES_THIS_DISK] = dircount
    endrec[_ECD_ENTRIES_TOTAL] = dircount2
    endrec[_ECD_SIZE] = dirsize
    endrec[_ECD_OFFSET] = diroffset
    return endrec


def _EndRecData(fpin):
    """Return data from the "End of Central Directory" record, or None.

    The data is a list of the nine items in the ZIP "End of central dir"
    record followed by a tenth item, the file seek offset of this record."""

    # Determine file size
    fpin.seek(0, 2)
    filesize = fpin.tell()

    # Check to see if this is ZIP file with no archive comment (the
    # "end of central directory" structure should be the last item in the
    # file if this is the case).
    try:
        fpin.seek(-sizeEndCentDir, 2)
    except OSError:
        return None
    data = fpin.read()
    if (len(data) == sizeEndCentDir and
            data[0:4] == stringEndArchive and
            data[-2:] == b"\000\000"):
        # the signature is correct and there's no comment, unpack structure
        endrec = struct.unpack(structEndArchive, data)
        endrec = list(endrec)

        # Append a blank comment and record start offset
        endrec.append(b"")
        endrec.append(filesize - sizeEndCentDir)

        # Try to read the "Zip64 end of central directory" structure
        return _EndRecData64(fpin, -sizeEndCentDir, endrec)

    # Either this is not a ZIP file, or it is a ZIP file with an archive
    # comment.  Search the end of the file for the "end of central directory"
    # record signature. The comment is the last item in the ZIP file and may be
    # up to 64K long.  It is assumed that the "end of central directory" magic
    # number does not appear in the comment.
    maxCommentStart = max(filesize - (1 << 16) - sizeEndCentDir, 0)
    fpin.seek(maxCommentStart, 0)
    data = fpin.read()
    start = data.rfind(stringEndArchive)
    if start >= 0:
        # found the magic number; attempt to unpack and interpret
        recData = data[start:start+sizeEndCentDir]
        if len(recData) != sizeEndCentDir:
            # Zip file is corrupted.
            return None
        endrec = list(struct.unpack(structEndArchive, recData))
        commentSize = endrec[_ECD_COMMENT_SIZE]  # as claimed by the zip file
        comment = data[start+sizeEndCentDir:start+sizeEndCentDir+commentSize]
        endrec.append(comment)
        endrec.append(maxCommentStart + start)

        # Try to read the "Zip64 end of central directory" structure
        return _EndRecData64(fpin, maxCommentStart + start - filesize,
                             endrec)

    # Unable to find a valid end of central directory structure
    return None


class ZipInfo (object):
    """Class with attributes describing each file in the ZIP archive."""

    __slots__ = (
        'orig_filename',
        'filename',
        'date_time',
        'compress_type',
        '_compresslevel',
        'comment',
        'extra',
        'create_system',
        'create_version',
        'extract_version',
        'reserved',
        'flag_bits',
        'volume',
        'internal_attr',
        'external_attr',
        'header_offset',
        'CRC',
        'compress_size',
        'file_size',
        '_raw_time',
    )

    def __init__(self, filename="NoName", date_time=(1980, 1, 1, 0, 0, 0)):
        self.orig_filename = filename   # Original file name in archive

        # Terminate the file name at the first null byte.  Null bytes in file
        # names are used as tricks by viruses in archives.
        null_byte = filename.find(chr(0))
        if null_byte >= 0:
            filename = filename[0:null_byte]
        # This is used to ensure paths in generated ZIP files always use
        # forward slashes as the directory separator, as required by the
        # ZIP format specification.
        if os.sep != "/" and os.sep in filename:
            filename = filename.replace(os.sep, "/")

        self.filename = filename        # Normalized file name
        self.date_time = date_time      # year, month, day, hour, min, sec

        if date_time[0] < 1980:
            raise ValueError('ZIP does not support timestamps before 1980')

        # Standard values:
        self.compress_type = ZIP_STORED  # Type of compression for the file
        self._compresslevel = None       # Level for the compressor
        self.comment = b""               # Comment for each file
        self.extra = b""                 # ZIP extra data
        if sys.platform == 'win32':
            self.create_system = 0          # System which created ZIP archive
        else:
            # Assume everything else is unix-y
            self.create_system = 3              # System which created ZIP archive
        self.create_version = DEFAULT_VERSION   # Version which created ZIP archive
        self.extract_version = DEFAULT_VERSION  # Version needed to extract archive
        self.reserved = 0                       # Must be zero
        self.flag_bits = 0                      # ZIP flag bits
        self.volume = 0                         # Volume number of file header
        self.internal_attr = 0                  # Internal attributes
        self.external_attr = 0                  # External file attributes
        # Other attributes are set by class ZipFile:
        # header_offset         Byte offset to the file header
        # CRC                   CRC-32 of the uncompressed file
        # compress_size         Size of the compressed file
        # file_size             Size of the uncompressed file

    def __repr__(self):
        result = ['<%s filename=%r' % (self.__class__.__name__, self.filename)]
        if self.compress_type != ZIP_STORED:
            result.append(' compress_type=%s' %
                          compressor_names.get(self.compress_type,
                                               self.compress_type))
        hi = self.external_attr >> 16
        lo = self.external_attr & 0xFFFF
        if hi:
            result.append(' filemode=%r' % stat.filemode(hi))
        if lo:
            result.append(' external_attr=%#x' % lo)
        isdir = self.is_dir()
        if not isdir or self.file_size:
            result.append(' file_size=%r' % self.file_size)
        if ((not isdir or self.compress_size) and
            (self.compress_type != ZIP_STORED or
             self.file_size != self.compress_size)):
            result.append(' compress_size=%r' % self.compress_size)
        result.append('>')
        return ''.join(result)

    @property
    def is_encrypted(self):
        return self.flag_bits & _MASK_ENCRYPTED

    @property
    def is_utf_filename(self):
        """Return True if filenames are encoded in UTF-8.

        Bit 11: Language encoding flag (EFS).  If this bit is set, the filename
        and comment fields for this file MUST be encoded using UTF-8.
        """
        return self.flag_bits & _MASK_UTF_FILENAME

    @property
    def is_compressed_patch_data(self):
        # Zip 2.7: compressed patched data
        return self.flag_bits & _MASK_COMPRESSED_PATCH

    @property
    def is_strong_encryption(self):
        return self.flag_bits & _MASK_STRONG_ENCRYPTION

    @property
    def use_datadescripter(self):
        """Returns True if datadescripter is in use.

        If bit 3 of flags is set, the data descripter is must exist.  It is
        byte aligned and immediately follows the last byte of compressed data.

        crc-32                          4 bytes
        compressed size                 4 bytes
        uncompressed size               4 bytes
        """
        return self.flag_bits & _MASK_USE_DATA_DESCRIPTOR

    def encode_datadescripter(self, zip64, crc, compress_size, file_size):
        fmt = '<LLQQ' if zip64 else '<LLLL'
        return struct.pack(fmt, _DD_SIGNATURE, crc, compress_size, file_size)

    def datadescripter(self, zip64):
        return self.encode_datadescripter(
            zip64, self.CRC, self.compress_size, self.file_size)

    def get_dosdate(self):
        dt = self.date_time
        return (dt[0] - 1980) << 9 | dt[1] << 5 | dt[2]

    def get_dostime(self):
        dt = self.date_time
        return dt[3] << 11 | dt[4] << 5 | (dt[5] // 2)

    def encode_local_header(self, *, filename, extract_version, reserved,
                            flag_bits, compress_type, dostime, dosdate, crc,
                            compress_size, file_size, extra):
        header = struct.pack(
            structFileHeader,
            stringFileHeader,
            extract_version,
            reserved,
            flag_bits,
            compress_type,
            dostime,
            dosdate,
            crc,
            compress_size,
            file_size,
            len(filename),
            len(extra)
        )
        return header + filename + extra

    def zip64_local_header(self, zip64, file_size, compress_size):
        """If zip64 is required, return encoded extra block and other
        parameters which may alter the local file header.

        The local zip64 entry requires that, if the zip64 block is present, it
        must contain both file_size and compress_size. This is different to the
        central directory zip64 extra block which requires only fields which
        need the extra zip64 size be present in the extra block.
        """
        min_version = 0
        extra = b''
        requires_zip64 = file_size > ZIP64_LIMIT or compress_size > ZIP64_LIMIT
        if zip64 is None:
            zip64 = requires_zip64
        if zip64:
            extra = struct.pack(
                '<HHQQ',
                EXTRA_ZIP64,
                8*2,  # QQ
                file_size,
                compress_size)
        if requires_zip64:
            if not zip64:
                raise LargeZipFile("Filesize would require ZIP64 extensions")
            # File is larger than what fits into a 4 byte integer,
            # fall back to the ZIP64 extension
            file_size = 0xffffffff
            compress_size = 0xffffffff
            min_version = ZIP64_VERSION
        return extra, file_size, compress_size, min_version

    def zip64_central_header(self):
        zip64_fields = []
        if self.file_size > ZIP64_LIMIT:
            zip64_fields.append(self.file_size)
            file_size = 0xffffffff
        else:
            file_size = self.file_size

        if self.compress_size > ZIP64_LIMIT:
            zip64_fields.append(self.compress_size)
            compress_size = 0xffffffff
        else:
            compress_size = self.compress_size

        if self.header_offset > ZIP64_LIMIT:
            zip64_fields.append(self.header_offset)
            header_offset = 0xffffffff
        else:
            header_offset = self.header_offset

        # For completeness - We don't support writing disks with multiple parts
        # so the number of disks is always going to be 0. Definitely not
        # more than 65,535.
        # ZIP64_DISK_LIMIT = (1 << 16) - 1
        # if self.disk_start > ZIP64_DISK_LIMIT:
        #     zip64_fields.append(self.disk_start)
        #     disk_num = 0xffff
        # else:
        #     header_offset = self.disk_start

        min_version = 0
        if zip64_fields:
            extra = struct.pack(
                '<HH' + 'Q'*len(zip64_fields),
                EXTRA_ZIP64,
                8*len(zip64_fields),
                *zip64_fields)
            min_version = ZIP64_VERSION
        else:
            extra = b''
        return extra, file_size, compress_size, header_offset, min_version

    def FileHeader(self, zip64=None):
        """Return the per-file header as a string."""
        dosdate = self.get_dosdate()
        dostime = self.get_dostime()
        if self.use_datadescripter:
            # Set these to zero because we write them after the file data
            CRC = compress_size = file_size = 0
        else:
            CRC = self.CRC
            compress_size = self.compress_size
            file_size = self.file_size

        # Always write ZIP64 back to the start of the extra block for
        # compatability with windows 7.
        min_version = 0
        (extra,
         file_size,
         compress_size,
         zip64_min_version,
         ) = self.zip64_local_header(zip64, file_size, compress_size)
        min_version = min(min_version, zip64_min_version)

        if self.compress_type == ZIP_BZIP2:
            min_version = max(BZIP2_VERSION, min_version)
        elif self.compress_type == ZIP_LZMA:
            min_version = max(LZMA_VERSION, min_version)

        self.extract_version = max(min_version, self.extract_version)
        self.create_version = max(min_version, self.create_version)
        filename, flag_bits = self._encodeFilenameFlags()
        return self.encode_local_header(
            filename=filename,
            extract_version=self.extract_version,
            reserved=self.reserved,
            flag_bits=flag_bits,
            compress_type=self.compress_type,
            dostime=dostime,
            dosdate=dosdate,
            crc=CRC,
            compress_size=compress_size,
            file_size=file_size,
            extra=extra
        )

    def encode_central_directory(self, filename, create_version, create_system,
                                 extract_version, reserved, flag_bits,
                                 compress_type, dostime, dosdate, crc,
                                 compress_size, file_size, disk_start,
                                 internal_attr, external_attr, header_offset,
                                 extra_data, comment):
        try:
            centdir = struct.pack(
                structCentralDir,
                stringCentralDir,
                create_version,
                create_system,
                extract_version,
                reserved,
                flag_bits,
                compress_type,
                dostime,
                dosdate,
                crc,
                compress_size,
                file_size,
                len(filename),
                len(extra_data),
                len(comment),
                disk_start,
                internal_attr,
                external_attr,
                header_offset)
        except DeprecationWarning:
            # Is this for python 3.0 where struct would raise a
            # DeprecationWarning instead of a struct.error when an integer
            # conversion code was passed a non-integer?
            # Is it still needed?
            print((structCentralDir, stringCentralDir, create_version,
                   create_system, extract_version, reserved,
                   flag_bits, compress_type, dostime, dosdate,
                   crc, compress_size, file_size,
                   len(filename), len(extra_data), len(comment),
                   disk_start, internal_attr, external_attr,
                   header_offset), file=sys.stderr)
            raise
        return centdir, filename, extra_data

    def central_directory(self):
        dosdate = self.get_dosdate()
        dostime = self.get_dostime()

        # Always write ZIP64 back to the start of the extra block for
        # compatability with windows 7.
        (extra_data,
         file_size,
         compress_size,
         header_offset,
         min_version,
         ) = self.zip64_central_header()

        if self.compress_type == ZIP_BZIP2:
            min_version = max(BZIP2_VERSION, min_version)
        elif self.compress_type == ZIP_LZMA:
            min_version = max(LZMA_VERSION, min_version)

        extract_version = max(min_version, self.extract_version)
        create_version = max(min_version, self.create_version)
        filename, flag_bits = self._encodeFilenameFlags()
        # Writing multi disk archives is not supported so disks is always 0
        disk_start = 0
        return self.encode_central_directory(
            filename=filename,
            create_version=create_version,
            create_system=self.create_system,
            extract_version=extract_version,
            reserved=self.reserved,
            flag_bits=flag_bits,
            compress_type=self.compress_type,
            dostime=dostime,
            dosdate=dosdate,
            crc=self.CRC,
            compress_size=compress_size,
            file_size=file_size,
            disk_start=disk_start,
            internal_attr=self.internal_attr,
            external_attr=self.external_attr,
            header_offset=header_offset,
            extra_data=extra_data,
            comment=self.comment)

    def _encodeFilenameFlags(self):
        try:
            return self.filename.encode('ascii'), self.flag_bits
        except UnicodeEncodeError:
            return (
                self.filename.encode('utf-8'),
                self.flag_bits | _MASK_UTF_FILENAME
            )

    def decode_extra_zip64(self, ln, extra, is_central_directory=True):

        # offset = len(extra block tag) + len(extra block size)
        offset = 4

        # Unpack the extra block from one of the possiblities given the
        # combinations of a struct 'QQQL' where every field is optional.
        if ln == 0:
            counts = ()
        elif ln in {8, 16, 24}:
            field_cnt = ln / 8
            counts = struct.unpack('<%dQ' % field_cnt, extra[offset:offset+ln])
        elif ln in {4, 12, 20, 28}:
            q_field_cnt = (ln - 4) / 8
            if q_field_cnt == 0:
                struct_str = '<I'
            else:
                struct_str = '<%dQI' % (q_field_cnt, )
            counts = struct.unpack(struct_str, extra[offset:offset+ln])

        else:
            raise BadZipFile(
                "Corrupt extra field %04x (size=%d)" % (EXTRA_ZIP64, ln)
            )

        zip64_field_cnt = 0
        # ZIP64 extension (large files and/or large archives)
        try:
            if self.file_size in (0xffffffffffffffff, 0xffffffff):
                field = "File size"
                self.file_size = counts[zip64_field_cnt]
                zip64_field_cnt += 1

            if self.compress_size == 0xffffffff:
                field = "Compress size"
                self.compress_size = counts[zip64_field_cnt]
                zip64_field_cnt += 1

            if is_central_directory:
                if self.header_offset == 0xffffffff:
                    field = "Header offset"
                    self.header_offset = counts[zip64_field_cnt]
                    zip64_field_cnt += 1

                # For completeness - The spec defines a way for handling a larger
                # number of disks than can fit into 2 bytes. As zipfile currently
                # doesn't support multiple disks we don't do anything with this
                # field.
                # if self.diskno == 0xffff:
                #     field = "Disk number"
                #     self.diskno = counts[zip64_field_cnt]
                #     zip64_field_cnt += 1
        except IndexError:
            raise BadZipFile(
                "Corrupt zip64 extra field. {} not found.".format(field)
            ) from None

    def get_extra_decoders(self):
        return {
            EXTRA_ZIP64: self.decode_extra_zip64,
        }

    def _decodeExtra(self):
        # Try to decode the extra field.
        extra = self.extra
        extra_decoders = self.get_extra_decoders()
        while len(extra) >= 4:
            tp, ln = struct.unpack('<HH', extra[:4])
            if ln+4 > len(extra):
                raise BadZipFile(
                    "Corrupt extra field %04x (size=%d)" % (tp, ln)
                )
            try:
                extra_decoders[tp](ln, extra)
            except KeyError:
                # We don't support this particular Extra Data field
                pass
            extra = extra[ln+4:]

    @classmethod
    def from_file(cls, filename, arcname=None, *, strict_timestamps=True):
        """Construct an appropriate ZipInfo for a file on the filesystem.

        filename should be the path to a file or directory on the filesystem.

        arcname is the name which it will have within the archive (by default,
        this will be the same as filename, but without a drive letter and with
        leading path separators removed).
        """

        # os.PathLike and os.fspath were added in python 3.6
        if sys.version_info[0:2] >= (3, 6):
            if isinstance(filename, os.PathLike):
                filename = os.fspath(filename)
        else:
            if isinstance(filename, pathlib.PurePath):
                filename = str(filename)
        st = os.stat(filename)
        isdir = stat.S_ISDIR(st.st_mode)
        mtime = time.localtime(st.st_mtime)
        date_time = mtime[0:6]
        if not strict_timestamps and date_time[0] < 1980:
            date_time = (1980, 1, 1, 0, 0, 0)
        elif not strict_timestamps and date_time[0] > 2107:
            date_time = (2107, 12, 31, 23, 59, 59)
        # Create ZipInfo instance to store file information
        if arcname is None:
            arcname = filename
        arcname = os.path.normpath(os.path.splitdrive(arcname)[1])
        while arcname[0] in (os.sep, os.altsep):
            arcname = arcname[1:]
        if isdir:
            arcname += '/'
        zinfo = cls(arcname, date_time)
        zinfo.external_attr = (st.st_mode & 0xFFFF) << 16  # Unix attributes
        if isdir:
            zinfo.file_size = 0
            zinfo.external_attr |= 0x10  # MS-DOS directory flag
        else:
            zinfo.file_size = st.st_size

        return zinfo

    def is_dir(self):
        """Return True if this archive member is a directory."""
        return self.filename[-1] == '/'


# ZIP encryption uses the CRC32 one-byte primitive for scrambling some
# internal keys. We noticed that a direct implementation is faster than
# relying on binascii.crc32().

_crctable = None


def _gen_crc(crc):
    for j in range(8):
        if crc & 1:
            crc = (crc >> 1) ^ 0xEDB88320
        else:
            crc >>= 1
    return crc


class BaseZipDecrypter:

    def decrypt(self, data):
        raise NotImplementedError(
            'BaseZipDecrypter implementations must implement `decrypt`.'
        )


class CRCZipDecrypter(BaseZipDecrypter):
    """PKWARE Encryption Decrypter

    ZIP supports a password-based form of encryption. Even though known
    plaintext attacks have been found against it, it is still useful
    to be able to get data out of such a file.

    Usage:
        zd = CRCZipDecrypter(zinfo, mypwd, encryption_header)
        plain_bytes = zd.decrypt(cypher_bytes)
    """

    encryption_header_length = 12

    def __init__(self, zinfo, pwd, encryption_header):

        self.key0 = 305419896
        self.key1 = 591751049
        self.key2 = 878082192

        global _crctable
        if _crctable is None:
            _crctable = list(map(_gen_crc, range(256)))
        self.crctable = _crctable

        for p in pwd:
            self.update_keys(p)

        # The first 12 bytes in the cypher stream is an encryption header
        #  used to strengthen the algorithm. The first 11 bytes are
        #  completely random, while the 12th contains the MSB of the CRC,
        #  or the MSB of the file time depending on the header type
        #  and is used to check the correctness of the password.
        h = self.decrypt(encryption_header[0:12])
        if zinfo.use_datadescripter:
            # compare against the file type from extended local headers
            check_byte = (zinfo._raw_time >> 8) & 0xff
        else:
            # compare against the CRC otherwise
            check_byte = (zinfo.CRC >> 24) & 0xff
        if h[11] != check_byte:
            raise RuntimeError("Bad password for file %r" % zinfo.filename)

    def crc32(self, ch, crc):
        """Compute the CRC32 primitive on one byte."""
        return (crc >> 8) ^ self.crctable[(crc ^ ch) & 0xFF]

    def update_keys(self, c):
        self.key0 = self.crc32(c, self.key0)
        self.key1 = (self.key1 + (self.key0 & 0xFF)) & 0xFFFFFFFF
        self.key1 = (self.key1 * 134775813 + 1) & 0xFFFFFFFF
        self.key2 = self.crc32(self.key1 >> 24, self.key2)

    def decrypt(self, data):
        """Decrypt a bytes object."""
        result = bytearray()
        append = result.append
        for c in data:
            k = self.key2 | 2
            c ^= ((k * (k ^ 1)) >> 8) & 0xFF
            self.update_keys(c)
            append(c)
        return bytes(result)


class LZMACompressor:
    # The LZMA SDK version is not related to the XZ Util's liblzma version that
    # the python library links to. The LZMA SDK is associated with the 7-zip
    # project by Igor Pavlov. If there is a breaking change in how the
    # properties are packed or their contents, these version identifiers can be
    # used to specify the strategy for decompression. While the version of the
    # LZMA SDK changes with each new version of 7zip, I don't believe there has
    # been any breaking changes since the version supplied here (but I haven't
    # spent much time confirming if that is true).
    LZMA_SDK_MAJOR_VERSION = 9
    LZMA_SDK_MINOR_VERSION = 4

    def __init__(self):
        self._comp = None

    def _init(self):
        props = lzma._encode_filter_properties({'id': lzma.FILTER_LZMA1})
        self._comp = lzma.LZMACompressor(lzma.FORMAT_RAW, filters=[
            lzma._decode_filter_properties(lzma.FILTER_LZMA1, props)
        ])
        header = struct.pack(
            '<BBH',
            self.LZMA_SDK_MAJOR_VERSION,
            self.LZMA_SDK_MINOR_VERSION,
            len(props)
        ) + props
        return header

    def compress(self, data):
        if self._comp is None:
            return self._init() + self._comp.compress(data)
        return self._comp.compress(data)

    def flush(self):
        if self._comp is None:
            return self._init() + self._comp.flush()
        return self._comp.flush()


class LZMADecompressor:
    # By itself, this decompressor needs an end of stream marker to know when
    # the compressed stream has finished. If there is no end of stream marker,
    # but the zip file length is known, the file can still be processed by
    # ensuring we only pass data to the length of 'compress_size' to the
    # decompressor.
    #
    # There should be a check to make sure either the end of stream marker flag
    # is set or the 'compress_size' is provided to catch malformed files.
    #
    # https://sourceforge.net/p/lzmautils/discussion/708858/thread/da2a47a8/
    # (2011-12-06)
    # "The raw decoder API works only with streams that have end of
    # payload/stream marker. The raw stream APIs don't support much else than
    # what would be valid inside a .xz file.
    # The .lzma file decoder (lzma_alone_decoder) works with files that have a
    # known size in the header and no end marker. It's handled as a special
    # case internally and is not exported to raw decoder API; maybe it should
    # be."

    def __init__(self):
        self._decomp = None
        self._unconsumed = b''
        self.eof = False

    def decompress(self, data):
        if self._decomp is None:
            self._unconsumed += data
            if len(self._unconsumed) <= 4:
                return b''
            major_version, minor_version, psize = struct.unpack(
                '<BBH', self._unconsumed[:4])
            if len(self._unconsumed) <= 4 + psize:
                return b''

            self._decomp = lzma.LZMADecompressor(lzma.FORMAT_RAW, filters=[
                lzma._decode_filter_properties(lzma.FILTER_LZMA1,
                                               self._unconsumed[4:4 + psize])
            ])
            data = self._unconsumed[4 + psize:]
            del self._unconsumed

        result = self._decomp.decompress(data)
        self.eof = self._decomp.eof
        return result


compressor_names = {
    0: 'store',
    1: 'shrink',
    2: 'reduce',
    3: 'reduce',
    4: 'reduce',
    5: 'reduce',
    6: 'implode',
    7: 'tokenize',
    8: 'deflate',
    9: 'deflate64',
    10: 'implode',
    12: 'bzip2',
    14: 'lzma',
    18: 'terse',
    19: 'lz77',
    97: 'wavpack',
    98: 'ppmd',
}


def _check_compression(compression):
    if compression == ZIP_STORED:
        pass
    elif compression == ZIP_DEFLATED:
        if not zlib:
            raise RuntimeError(
                "Compression requires the (missing) zlib module")
    elif compression == ZIP_BZIP2:
        if not bz2:
            raise RuntimeError(
                "Compression requires the (missing) bz2 module")
    elif compression == ZIP_LZMA:
        if not lzma:
            raise RuntimeError(
                "Compression requires the (missing) lzma module")
    else:
        raise NotImplementedError("That compression method is not supported")


def _get_compressor(compress_type, compresslevel=None):
    if compress_type == ZIP_DEFLATED:
        if compresslevel is not None:
            return zlib.compressobj(compresslevel, zlib.DEFLATED, -15)
        return zlib.compressobj(zlib.Z_DEFAULT_COMPRESSION, zlib.DEFLATED, -15)
    elif compress_type == ZIP_BZIP2:
        if compresslevel is not None:
            return bz2.BZ2Compressor(compresslevel)
        return bz2.BZ2Compressor()
    # compresslevel is ignored for ZIP_LZMA
    elif compress_type == ZIP_LZMA:
        return LZMACompressor()
    else:
        return None


class _SharedFile:
    def __init__(self, file, pos, close, lock, writing):
        self._file = file
        self._pos = pos
        self._close = close
        self._lock = lock
        self._writing = writing
        self.seekable = file.seekable
        self.tell = file.tell

    def seek(self, offset, whence=0):
        with self._lock:
            if self._writing():
                raise ValueError("Can't reposition in the ZIP file while "
                                 "there is an open writing handle on it. "
                                 "Close the writing handle before trying to read.")
            self._file.seek(offset, whence)
            self._pos = self._file.tell()
            return self._pos

    def read(self, n=-1):
        with self._lock:
            if self._writing():
                raise ValueError("Can't read from the ZIP file while there "
                                 "is an open writing handle on it. "
                                 "Close the writing handle before trying to read.")
            self._file.seek(self._pos)
            data = self._file.read(n)
            self._pos = self._file.tell()
            return data

    def close(self):
        if self._file is not None:
            fileobj = self._file
            self._file = None
            self._close(fileobj)


# Provide the tell method for unseekable stream
class _Tellable:
    def __init__(self, fp):
        self.fp = fp
        self.offset = 0

    def write(self, data):
        n = self.fp.write(data)
        self.offset += n
        return n

    def tell(self):
        return self.offset

    def flush(self):
        self.fp.flush()

    def close(self):
        self.fp.close()


class ZipExtFile(io.BufferedIOBase):
    """File-like object for reading an archive member.

    Is returned by ZipFile.open().

    Responsible for reading the following parts of a zip file:

        [local file header]
        [encryption header]
        [file data]
        [data descriptor]

    For symmetry, the _ZipWriteFile class is responsible for writing the same
    sections.
    """

    # Max size supported by decompressor.
    MAX_N = 1 << 31 - 1

    # Read from compressed files in 4k blocks.
    MIN_READ_SIZE = 4096

    # Chunk size to read during seek
    MAX_SEEK_READ = 1 << 24

    def __init__(self, fileobj, mode, zipinfo, close_fileobj=False, pwd=None):
        self._fileobj = fileobj
        self._zinfo = zipinfo
        self._close_fileobj = close_fileobj
        self._pwd = pwd

        self.process_local_header()
        self.raise_for_unsupported_flags()

        self._compress_type = zipinfo.compress_type
        self._orig_compress_left = zipinfo.compress_size
        self.newlines = None

        self.mode = mode
        self.name = zipinfo.filename

        if hasattr(zipinfo, 'CRC'):
            self._expected_crc = zipinfo.CRC
            self._orig_start_crc = crc32(b'')
        else:
            self._expected_crc = None
            self._orig_start_crc = None

        self._seekable = False
        try:
            if fileobj.seekable():
                self._seekable = True
        except AttributeError:
            pass

        if self._zinfo.is_encrypted:
            self._decrypter_cls = self.setup_decrypter()
        else:
            self._decrypter_cls = None
        # Compress start is the start of the file data. It is after any
        # encryption header, if the encryption_header is present.
        self._compress_start = fileobj.tell()
        self.read_init()

    def read_init(self):
        self._running_crc = self._orig_start_crc
        # Remaining compressed bytes remaining to be read.
        self._compress_left = self._orig_compress_left
        # Remaining number of uncompressed bytes not returned to the calling
        # application.
        self._left = self._zinfo.file_size
        # Uncompressed data ready to return to the calling application.
        self._readbuffer = b''
        # The current position in _readbuffer for the next byte to return.
        self._offset = 0
        self._eof = False

        self._decrypter = self.get_decrypter()
        self._decompressor = self.get_decompressor(self._compress_type)

    def process_local_header(self):
        """Read the local header and raise for any errors.

        The local header is largely a duplicate of the file's entry in the
        central directory. Where it differs, the local header generally
        contains less information than the entry in the central directory.

        Currently we only use the local header data to check for errors.
        """
        # Skip the file header:
        fheader = self._fileobj.read(sizeFileHeader)
        if len(fheader) != sizeFileHeader:
            raise BadZipFile("Truncated file header")
        fheader = struct.unpack(structFileHeader, fheader)
        if fheader[_FH_SIGNATURE] != stringFileHeader:
            raise BadZipFile("Bad magic number for file header")

        fname = self._fileobj.read(fheader[_FH_FILENAME_LENGTH])
        if fheader[_FH_EXTRA_FIELD_LENGTH]:
            self._fileobj.read(fheader[_FH_EXTRA_FIELD_LENGTH])

        if self._zinfo.is_utf_filename:
            # UTF-8 filename
            fname_str = fname.decode("utf-8")
        else:
            fname_str = fname.decode("cp437")

        if fname_str != self._zinfo.orig_filename:
            raise BadZipFile(
                'File name in directory %r and header %r differ.'
                % (self._zinfo.orig_filename, fname))

    def raise_for_unsupported_flags(self):
        if self._zinfo.is_compressed_patch_data:
            # Zip 2.7: compressed patched data
            raise NotImplementedError("compressed patched data (flag bit 5)")

        if self._zinfo.is_strong_encryption:
            # strong encryption
            raise NotImplementedError("strong encryption (flag bit 6)")

    def get_decompressor(self, compress_type):
        if compress_type == ZIP_STORED:
            return None
        elif compress_type == ZIP_DEFLATED:
            return zlib.decompressobj(-15)
        elif compress_type == ZIP_BZIP2:
            return bz2.BZ2Decompressor()
        elif compress_type == ZIP_LZMA:
            return LZMADecompressor()
        else:
            descr = compressor_names.get(compress_type)
            if descr:
                raise NotImplementedError(
                    "compression type %d (%s)" % (compress_type, descr)
                )
            else:
                raise NotImplementedError(
                    "compression type %d" % (compress_type,)
                )

    def setup_crczipdecrypter(self):
        if not self._pwd:
            raise RuntimeError("File %r is encrypted, password "
                               "required for extraction" % self.name)

        self.encryption_header = self._fileobj.read(
            CRCZipDecrypter.encryption_header_length)
        # Adjust read size for encrypted files since the start of the file
        # may be used for the encryption/password information.
        self._orig_compress_left -= CRCZipDecrypter.encryption_header_length
        return CRCZipDecrypter

    def setup_decrypter(self):
        return self.setup_crczipdecrypter()

    def get_decrypter_kwargs(self):
        return {
            'pwd': self._pwd,
            'encryption_header': self.encryption_header,
        }

    def get_decrypter(self):
        decrypter = None
        if self._decrypter_cls is not None:
            decrypter = self._decrypter_cls(
                self._zinfo,
                **self.get_decrypter_kwargs()
            )
        return decrypter

    def __repr__(self):
        result = ['<%s.%s' % (self.__class__.__module__,
                              self.__class__.__qualname__)]
        if not self.closed:
            result.append(' name=%r mode=%r' % (self.name, self.mode))
            if self._compress_type != ZIP_STORED:
                result.append(' compress_type=%s' %
                              compressor_names.get(self._compress_type,
                                                   self._compress_type))
        else:
            result.append(' [closed]')
        result.append('>')
        return ''.join(result)

    def readline(self, limit=-1):
        """Read and return a line from the stream.

        If limit is specified, at most limit bytes will be read.
        """

        if limit < 0:
            # Shortcut common case - newline found in buffer.
            i = self._readbuffer.find(b'\n', self._offset) + 1
            if i > 0:
                line = self._readbuffer[self._offset: i]
                self._offset = i
                return line

        return io.BufferedIOBase.readline(self, limit)

    def peek(self, n=1):
        """Returns buffered bytes without advancing the position."""
        if n > len(self._readbuffer) - self._offset:
            chunk = self.read(n)
            if len(chunk) > self._offset:
                self._readbuffer = chunk + self._readbuffer[self._offset:]
                self._offset = 0
            else:
                self._offset -= len(chunk)

        # Return up to 512 bytes to reduce allocation overhead for tight loops.
        return self._readbuffer[self._offset: self._offset + 512]

    def readable(self):
        return True

    def read(self, n=-1):
        """Read and return up to n bytes.

        If the argument is omitted, None, or negative, data is read and
        returned until EOF is reached.
        """
        if n is None or n < 0:
            buf = self._readbuffer[self._offset:]
            self._readbuffer = b''
            self._offset = 0
            while not self._eof:
                buf += self._read1(self.MAX_N)
            return buf

        end = n + self._offset
        if end < len(self._readbuffer):
            buf = self._readbuffer[self._offset:end]
            self._offset = end
            return buf

        n = end - len(self._readbuffer)
        buf = self._readbuffer[self._offset:]
        self._readbuffer = b''
        self._offset = 0
        while n > 0 and not self._eof:
            data = self._read1(n)
            if n < len(data):
                self._readbuffer = data
                self._offset = n
                buf += data[:n]
                break
            buf += data
            n -= len(data)
        return buf

    def _update_crc(self, newdata):
        # Update the CRC using the given data.
        if self._expected_crc is None:
            # No need to compute the CRC if we don't have a reference value
            return
        self._running_crc = crc32(newdata, self._running_crc)

    def check_crc(self):
        if self._expected_crc is None:
            # No need to compute the CRC if we don't have a reference value
            return
        # Check the CRC if we're at the end of the file
        if self._eof and self._running_crc != self._expected_crc:
            raise BadZipFile("Bad CRC-32 for file %r" % self.name)

    def check_integrity(self):
        self.check_crc()

    def read1(self, n):
        """Read up to n bytes with at most one read() system call."""

        if n is None or n < 0:
            buf = self._readbuffer[self._offset:]
            self._readbuffer = b''
            self._offset = 0
            while not self._eof:
                data = self._read1(self.MAX_N)
                if data:
                    buf += data
                    break
            return buf

        end = n + self._offset
        if end < len(self._readbuffer):
            buf = self._readbuffer[self._offset:end]
            self._offset = end
            return buf

        n = end - len(self._readbuffer)
        buf = self._readbuffer[self._offset:]
        self._readbuffer = b''
        self._offset = 0
        if n > 0:
            while not self._eof:
                data = self._read1(n)
                if n < len(data):
                    self._readbuffer = data
                    self._offset = n
                    buf += data[:n]
                    break
                if data:
                    buf += data
                    break
        return buf

    def _read1(self, n):
        # Read up to n compressed bytes with at most one read() system call,
        # decrypt and decompress them.
        if self._eof or n <= 0:
            return b''

        # Read from file.
        if self._compress_type == ZIP_DEFLATED:
            # Handle unconsumed data.
            data = self._decompressor.unconsumed_tail
            if n > len(data):
                data += self._read2(n - len(data))
        else:
            data = self._read2(n)

        if self._compress_type == ZIP_STORED:
            self._eof = self._compress_left <= 0
        elif self._compress_type == ZIP_DEFLATED:
            n = max(n, self.MIN_READ_SIZE)
            data = self._decompressor.decompress(data, n)
            self._eof = (self._decompressor.eof or
                         self._compress_left <= 0 and
                         not self._decompressor.unconsumed_tail)
            if self._eof:
                data += self._decompressor.flush()
        else:
            data = self._decompressor.decompress(data)
            self._eof = self._decompressor.eof or self._compress_left <= 0

        data = data[:self._left]
        self._left -= len(data)
        if self._left <= 0:
            self._eof = True
        self._update_crc(data)
        if self._eof:
            self.check_integrity()
        return data

    def _read2(self, n):
        if self._compress_left <= 0:
            return b''

        n = max(n, self.MIN_READ_SIZE)
        n = min(n, self._compress_left)

        data = self._fileobj.read(n)
        self._compress_left -= len(data)
        if not data:
            raise EOFError

        if self._decrypter is not None:
            data = self._decrypter.decrypt(data)
        return data

    def close(self):
        try:
            if self._close_fileobj:
                self._fileobj.close()
        finally:
            super().close()

    def seekable(self):
        return self._seekable

    def seek(self, offset, whence=0):
        if not self._seekable:
            raise io.UnsupportedOperation("underlying stream is not seekable")
        curr_pos = self.tell()
        if whence == 0:    # Seek from start of file
            new_pos = offset
        elif whence == 1:  # Seek from current position
            new_pos = curr_pos + offset
        elif whence == 2:  # Seek from EOF
            new_pos = self._zinfo.file_size + offset
        else:
            raise ValueError("whence must be os.SEEK_SET (0), "
                             "os.SEEK_CUR (1), or os.SEEK_END (2)")

        if new_pos > self._zinfo.file_size:
            new_pos = self._zinfo.file_size

        if new_pos < 0:
            new_pos = 0

        read_offset = new_pos - curr_pos
        buff_offset = read_offset + self._offset

        if buff_offset >= 0 and buff_offset < len(self._readbuffer):
            # Just move the _offset index if the new position is in the
            # _readbuffer
            self._offset = buff_offset
            read_offset = 0
        elif read_offset < 0:
            # Position is before the current position. Reset the ZipExtFile
            self._fileobj.seek(self._compress_start)
            self.read_init()
            read_offset = new_pos

        while read_offset > 0:
            read_len = min(self.MAX_SEEK_READ, read_offset)
            self.read(read_len)
            read_offset -= read_len

        return self.tell()

    def tell(self):
        if not self._seekable:
            raise io.UnsupportedOperation("underlying stream is not seekable")
        filepos = (
            self._zinfo.file_size - self._left - len(self._readbuffer)
            + self._offset
        )
        return filepos


class _ZipWriteFile(io.BufferedIOBase):
    def __init__(self, zf, zinfo, zip64, encrypter=None):
        self._zinfo = zinfo
        self._zip64 = zip64
        self._zipfile = zf
        self._compressor = _get_compressor(zinfo.compress_type,
                                           zinfo._compresslevel)
        self._encrypter = encrypter
        self._file_size = 0
        self._compress_size = 0
        self._crc = 0

        self.write_local_header()

        if self._encrypter:
            self.write_encryption_header()

    @property
    def _fileobj(self):
        return self._zipfile.fp

    def writable(self):
        return True

    def write_local_header(self):
        header = self._zinfo.FileHeader(self._zip64)
        # From this point onwards, we have likely altered the contents of the
        # file.
        self._zipfile._didModify = True
        self._zipfile._writing = True
        self._fileobj.write(header)

    def write_encryption_header(self):
        buf = self._encrypter.encryption_header()
        self._compress_size += len(buf)
        self._fileobj.write(buf)

    def write(self, data):
        if self.closed:
            raise ValueError('I/O operation on closed file.')
        nbytes = len(data)
        self._file_size += nbytes
        self._crc = crc32(data, self._crc)
        if self._compressor:
            data = self._compressor.compress(data)
        if self._encrypter:
            data = self._encrypter.encrypt(data)
        self._compress_size += len(data)
        self._fileobj.write(data)
        return nbytes

    def close(self):
        if self.closed:
            return
        super().close()
        # Flush any data from the compressor, and update header info
        if self._compressor:
            buf = self._compressor.flush()
        else:
            buf = b''
        if self._encrypter:
            buf = self._encrypter.encrypt(buf)
            buf += self._encrypter.flush()
        self._compress_size += len(buf)
        self._fileobj.write(buf)
        self._zinfo.compress_size = self._compress_size
        self._zinfo.CRC = self._crc
        self._zinfo.file_size = self._file_size

        if not self._zip64:
            if self._file_size > ZIP64_LIMIT:
                raise RuntimeError('File size unexpectedly exceeded ZIP64 '
                                   'limit')
            if self._compress_size > ZIP64_LIMIT:
                raise RuntimeError('Compressed size unexpectedly exceeded '
                                   'ZIP64 limit')

        # Write updated header info
        if self._zinfo.use_datadescripter:
            # Write CRC and file sizes after the file data
            self._fileobj.write(self._zinfo.datadescripter(self._zip64))
            self._zipfile.start_dir = self._fileobj.tell()
        else:
            # Seek backwards and write file header (which will now include
            # correct CRC and file sizes)

            # Preserve current position in file
            self._zipfile.start_dir = self._fileobj.tell()
            self._fileobj.seek(self._zinfo.header_offset)
            self._fileobj.write(self._zinfo.FileHeader(self._zip64))
            self._fileobj.seek(self._zipfile.start_dir)

        self._zipfile._writing = False

        # Successfully written: Add file to our caches
        self._zipfile.filelist.append(self._zinfo)
        self._zipfile.NameToInfo[self._zinfo.filename] = self._zinfo


# class ZipFile:
#     """ Class with methods to open, read, write, close, list zip files.

#     z = ZipFile(file, mode="r", compression=ZIP_STORED, allowZip64=True,
#                 compresslevel=None)

#     file: Either the path to the file, or a file-like object.
#           If it is a path, the file will be opened and closed by ZipFile.
#     mode: The mode can be either read 'r', write 'w', exclusive create 'x',
#           or append 'a'.
#     compression: ZIP_STORED (no compression), ZIP_DEFLATED (requires zlib),
#                  ZIP_BZIP2 (requires bz2) or ZIP_LZMA (requires lzma).
#     allowZip64: if True ZipFile will create files with ZIP64 extensions when
#                 needed, otherwise it will raise an exception when this would
#                 be necessary.
#     compresslevel: None (default for the given compression type) or an integer
#                    specifying the level to pass to the compressor.
#                    When using ZIP_STORED or ZIP_LZMA this keyword has no effect.
#                    When using ZIP_DEFLATED integers 0 through 9 are accepted.
#                    When using ZIP_BZIP2 integers 1 through 9 are accepted.

#     """

#     fp = None                   # Set here since __del__ checks it
#     _windows_illegal_name_trans_table = None
#     zipinfo_cls = ZipInfo
#     zipextfile_cls = ZipExtFile
#     zipwritefile_cls = _ZipWriteFile

#     def __init__(self, file, mode="r", compression=ZIP_STORED, allowZip64=True,
#                  compresslevel=None, *, strict_timestamps=True):
#         """Open the ZIP file with mode read 'r', write 'w', exclusive create
#         'x', or append 'a'."""
#         if mode not in ('r', 'w', 'x', 'a'):
#             raise ValueError("ZipFile requires mode 'r', 'w', 'x', or 'a'")

#         _check_compression(compression)

#         self._allowZip64 = allowZip64
#         self._didModify = False
#         self.debug = 0  # Level of printing: 0 through 3
#         self.NameToInfo = {}    # Find file info given name
#         self.filelist = []      # List of ZipInfo instances for archive
#         self.compression = compression  # Method of compression
#         self.compresslevel = compresslevel
#         self.mode = mode
#         self.pwd = None
#         self.encryption = None
#         self.encryption_kwargs = None
#         self._comment = b''
#         self._strict_timestamps = strict_timestamps

#         # Check if we were passed a file-like object
#         # os.PathLike and os.fspath were added in python 3.6
#         if sys.version_info[0:2] >= (3, 6):
#             if isinstance(file, os.PathLike):
#                 file = os.fspath(file)
#         else:
#             if isinstance(file, pathlib.PurePath):
#                 file = str(file)
#         if isinstance(file, str):
#             # No, it's a filename
#             self._filePassed = 0
#             self.filename = file
#             modeDict = {'r': 'rb', 'w': 'w+b', 'x': 'x+b', 'a': 'r+b',
#                         'r+b': 'w+b', 'w+b': 'wb', 'x+b': 'xb'}
#             filemode = modeDict[mode]
#             while True:
#                 try:
#                     self.fp = io.open(file, filemode)
#                 except OSError:
#                     if filemode in modeDict:
#                         filemode = modeDict[filemode]
#                         continue
#                     raise
#                 break
#         else:
#             self._filePassed = 1
#             self.fp = file
#             self.filename = getattr(file, 'name', None)
#         self._fileRefCnt = 1
#         self._lock = threading.RLock()
#         self._seekable = True
#         self._writing = False

#         try:
#             if mode == 'r':
#                 self._RealGetContents()
#             elif mode in ('w', 'x'):
#                 # set the modified flag so central directory gets written
#                 # even if no files are added to the archive
#                 self._didModify = True
#                 try:
#                     self.start_dir = self.fp.tell()
#                 except (AttributeError, OSError):
#                     self.fp = _Tellable(self.fp)
#                     self.start_dir = 0
#                     self._seekable = False
#                 else:
#                     # Some file-like objects can provide tell() but not seek()
#                     try:
#                         self.fp.seek(self.start_dir)
#                     except (AttributeError, OSError):
#                         self._seekable = False
#             elif mode == 'a':
#                 try:
#                     # See if file is a zip file
#                     self._RealGetContents()
#                     # seek to start of directory and overwrite
#                     self.fp.seek(self.start_dir)
#                 except BadZipFile:
#                     # file is not a zip file, just append
#                     self.fp.seek(0, 2)

#                     # set the modified flag so central directory gets written
#                     # even if no files are added to the archive
#                     self._didModify = True
#                     self.start_dir = self.fp.tell()
#             else:
#                 raise ValueError("Mode must be 'r', 'w', 'x', or 'a'")
#         except Exception as e:
#             fp = self.fp
#             self.fp = None
#             self._fpclose(fp)
#             raise e

#     def __enter__(self):
#         return self

#     def __exit__(self, type, value, traceback):
#         self.close()

#     def __repr__(self):
#         result = ['<%s.%s' % (self.__class__.__module__,
#                               self.__class__.__qualname__)]
#         if self.fp is not None:
#             if self._filePassed:
#                 result.append(' file=%r' % self.fp)
#             elif self.filename is not None:
#                 result.append(' filename=%r' % self.filename)
#             result.append(' mode=%r' % self.mode)
#         else:
#             result.append(' [closed]')
#         result.append('>')
#         return ''.join(result)

#     def _RealGetContents(self):
#         """Read in the table of contents for the ZIP file."""
#         fp = self.fp
#         try:
#             endrec = _EndRecData(fp)
#         except OSError:
#             raise BadZipFile("File is not a zip file")
#         if not endrec:
#             raise BadZipFile("File is not a zip file")
#         if self.debug > 1:
#             print(endrec)
#         size_cd = endrec[_ECD_SIZE]             # bytes in central directory
#         offset_cd = endrec[_ECD_OFFSET]         # offset of central directory
#         self._comment = endrec[_ECD_COMMENT]    # archive comment

#         # "concat" is zero, unless zip was concatenated to another file
#         concat = endrec[_ECD_LOCATION] - size_cd - offset_cd
#         if endrec[_ECD_SIGNATURE] == stringEndArchive64:
#             # If Zip64 extension structures are present, account for them
#             concat -= (sizeEndCentDir64 + sizeEndCentDir64Locator)

#         if self.debug > 2:
#             inferred = concat + offset_cd
#             print("given, inferred, offset", offset_cd, inferred, concat)
#         # self.start_dir:  Position of start of central directory
#         self.start_dir = offset_cd + concat
#         fp.seek(self.start_dir, 0)
#         data = fp.read(size_cd)
#         fp = io.BytesIO(data)
#         total = 0
#         while total < size_cd:
#             centdir = fp.read(sizeCentralDir)
#             if len(centdir) != sizeCentralDir:
#                 raise BadZipFile("Truncated central directory")
#             centdir = struct.unpack(structCentralDir, centdir)
#             if centdir[_CD_SIGNATURE] != stringCentralDir:
#                 raise BadZipFile("Bad magic number for central directory")
#             if self.debug > 2:
#                 print(centdir)
#             filename = fp.read(centdir[_CD_FILENAME_LENGTH])
#             flags = centdir[5]
#             if flags & _MASK_UTF_FILENAME:
#                 # UTF-8 file names extension
#                 filename = filename.decode('utf-8')
#             else:
#                 # Historical ZIP filename encoding
#                 filename = filename.decode('cp437')
#             # Create ZipInfo instance to store file information
#             x = self.zipinfo_cls(filename)
#             x.extra = fp.read(centdir[_CD_EXTRA_FIELD_LENGTH])
#             x.comment = fp.read(centdir[_CD_COMMENT_LENGTH])
#             x.header_offset = centdir[_CD_LOCAL_HEADER_OFFSET]
#             (x.create_version, x.create_system, x.extract_version, x.reserved,
#              x.flag_bits, x.compress_type, t, d,
#              x.CRC, x.compress_size, x.file_size) = centdir[1:12]
#             if x.extract_version > MAX_EXTRACT_VERSION:
#                 raise NotImplementedError("zip file version %.1f" %
#                                           (x.extract_version / 10))
#             x.volume, x.internal_attr, x.external_attr = centdir[15:18]
#             # Convert date/time code to (year, month, day, hour, min, sec)
#             x._raw_time = t
#             x.date_time = ((d >> 9)+1980, (d >> 5) & 0xF, d & 0x1F,
#                            t >> 11, (t >> 5) & 0x3F, (t & 0x1F) * 2)

#             x._decodeExtra()
#             x.header_offset = x.header_offset + concat
#             self.filelist.append(x)
#             self.NameToInfo[x.filename] = x

#             # update total bytes read from central directory
#             total = (total + sizeCentralDir + centdir[_CD_FILENAME_LENGTH]
#                      + centdir[_CD_EXTRA_FIELD_LENGTH]
#                      + centdir[_CD_COMMENT_LENGTH])

#             if self.debug > 2:
#                 print("total", total)

#     def namelist(self):
#         """Return a list of file names in the archive."""
#         return [data.filename for data in self.filelist]

#     def infolist(self):
#         """Return a list of class ZipInfo instances for files in the
#         archive."""
#         return self.filelist

#     def printdir(self, file=None):
#         """Print a table of contents for the zip file."""
#         print("%-46s %19s %12s" % ("File Name", "Modified    ", "Size"),
#               file=file)
#         for zinfo in self.filelist:
#             date = "%d-%02d-%02d %02d:%02d:%02d" % zinfo.date_time[:6]
#             print("%-46s %s %12d" % (zinfo.filename, date, zinfo.file_size),
#                   file=file)

#     def testzip(self):
#         """Read all the files and check the CRC."""
#         chunk_size = 2 ** 20
#         for zinfo in self.filelist:
#             try:
#                 # Read by chunks, to avoid an OverflowError or a
#                 # MemoryError with very large embedded files.
#                 with self.open(zinfo.filename, "r") as f:
#                     while f.read(chunk_size):     # Check CRC-32
#                         pass
#             except BadZipFile:
#                 return zinfo.filename

#     def getinfo(self, name):
#         """Return the instance of ZipInfo given 'name'."""
#         info = self.NameToInfo.get(name)
#         if info is None:
#             raise KeyError(
#                 'There is no item named %r in the archive' % name)

#         return info

#     def setpassword(self, pwd):
#         """Set default password for encrypted files."""
#         if pwd and not isinstance(pwd, bytes):
#             raise TypeError("pwd: expected bytes, got %s" % type(pwd).__name__)
#         if pwd:
#             self.pwd = pwd
#         else:
#             self.pwd = None

#     def setencryption(self, encryption, **kwargs):
#         self.encryption = encryption
#         self.encryption_kwargs = kwargs

#     def get_encrypter(self):
#         raise NotImplementedError("That encryption method is not supported")

#     @property
#     def comment(self):
#         """The comment text associated with the ZIP file."""
#         return self._comment

#     @comment.setter
#     def comment(self, comment):
#         if not isinstance(comment, bytes):
#             raise TypeError(
#                 "comment: expected bytes, got %s" % type(comment).__name__
#             )
#         # check for valid comment length
#         if len(comment) > ZIP_MAX_COMMENT:
#             import warnings
#             warnings.warn('Archive comment is too long; truncating to %d bytes'
#                           % ZIP_MAX_COMMENT, stacklevel=2)
#             comment = comment[:ZIP_MAX_COMMENT]
#         self._comment = comment
#         self._didModify = True

#     def read(self, name, pwd=None):
#         """Return file bytes (as a string) for name."""
#         with self.open(name, "r", pwd) as fp:
#             return fp.read()

#     def open(self, name, mode="r", pwd=None, *, force_zip64=False):
#         """Return file-like object for 'name'.

#         name is a string for the file name within the ZIP file, or a ZipInfo
#         object.

#         mode should be 'r' to read a file already in the ZIP file, or 'w' to
#         write to a file newly added to the archive.

#         pwd is the password to encrypt and decrypt files.

#         When writing, if the file size is not known in advance but may exceed
#         2 GiB, pass force_zip64 to use the ZIP64 format, which can handle large
#         files.  If the size is known in advance, it is best to pass a ZipInfo
#         instance for name, with zinfo.file_size set.
#         """
#         if mode not in {"r", "w"}:
#             raise ValueError('open() requires mode "r" or "w"')
#         if not self.fp:
#             raise ValueError(
#                 "Attempt to use ZIP archive that was already closed")

#         if not pwd:
#             pwd = self.pwd
#         if pwd and not isinstance(pwd, bytes):
#             raise TypeError("pwd: expected bytes, got %s" % type(pwd).__name__)

#         # Make sure we have an info object
#         if isinstance(name, self.zipinfo_cls):
#             # 'name' is already an info object
#             zinfo = name
#         elif mode == 'w':
#             zinfo = self.zipinfo_cls(name)
#             zinfo.compress_type = self.compression
#             zinfo._compresslevel = self.compresslevel
#         else:
#             # Get info object for name
#             zinfo = self.getinfo(name)

#         if mode == 'w':
#             return self._open_to_write(zinfo, force_zip64=force_zip64, pwd=pwd)

#         if self._writing:
#             raise ValueError("Can't read from the ZIP file while there "
#                              "is an open writing handle on it. "
#                              "Close the writing handle before trying to read.")

#         return self._open_to_read(mode, zinfo, pwd)

#     def _open_to_read(self, mode, zinfo, pwd):
#         # Open for reading:
#         self._fileRefCnt += 1
#         zef_file = _SharedFile(self.fp, zinfo.header_offset,
#                                self._fpclose, self._lock, lambda: self._writing)
#         try:
#             return self.zipextfile_cls(zef_file, mode, zinfo, True, pwd)
#         except Exception as e:
#             zef_file.close()
#             raise e

#     def _open_to_write(self, zinfo, force_zip64=False, pwd=None):
#         if force_zip64 and not self._allowZip64:
#             raise ValueError(
#                 "force_zip64 is True, but allowZip64 was False when opening "
#                 "the ZIP file."
#             )
#         if self._writing:
#             raise ValueError("Can't write to the ZIP file while there is "
#                              "another write handle open on it. "
#                              "Close the first handle before opening another.")

#         # Sizes and CRC are overwritten with correct data after processing the
#         # file
#         if not hasattr(zinfo, 'file_size'):
#             zinfo.file_size = 0
#         zinfo.compress_size = 0
#         zinfo.CRC = 0

#         zinfo.flag_bits = 0x00
#         encrypter = None
#         if pwd is not None or self.encryption is not None:
#             zinfo.flag_bits |= _MASK_ENCRYPTED
#             encrypter = self.get_encrypter()
#             encrypter.update_zipinfo(zinfo)
#         if zinfo.compress_type == ZIP_LZMA:
#             # Compressed data includes an end-of-stream (EOS) marker
#             zinfo.flag_bits |= _MASK_COMPRESS_OPTION_1
#         if not self._seekable:
#             zinfo.flag_bits |= _MASK_USE_DATA_DESCRIPTOR

#         if not zinfo.external_attr:
#             zinfo.external_attr = 0o600 << 16  # permissions: ?rw-------

#         # Compressed size can be larger than uncompressed size
#         zip64 = self._allowZip64 and \
#                 (force_zip64 or zinfo.file_size * 1.05 > ZIP64_LIMIT)  # noqa: E127

#         if self._seekable:
#             self.fp.seek(self.start_dir)
#         zinfo.header_offset = self.fp.tell()

#         self._writecheck(zinfo)
#         return self.zipwritefile_cls(self, zinfo, zip64, encrypter)

#     def extract(self, member, path=None, pwd=None):
#         """Extract a member from the archive to the current working directory,
#            using its full name. Its file information is extracted as accurately
#            as possible. `member` may be a filename or a ZipInfo object. You can
#            specify a different directory using `path`.
#         """
#         if path is None:
#             path = os.getcwd()
#         else:
#             # os.fspath were added in python 3.6
#             if sys.version_info[0:2] >= (3, 6):
#                 path = os.fspath(path)
#             else:
#                 path = str(path)

#         return self._extract_member(member, path, pwd)

#     def extractall(self, path=None, members=None, pwd=None):
#         """Extract all members from the archive to the current working
#            directory. `path` specifies a different directory to extract to.
#            `members` is optional and must be a subset of the list returned
#            by namelist().
#         """
#         if members is None:
#             members = self.namelist()

#         if path is None:
#             path = os.getcwd()
#         else:
#             # os.fspath were added in python 3.6
#             if sys.version_info[0:2] >= (3, 6):
#                 path = os.fspath(path)
#             else:
#                 path = str(path)

#         for zipinfo in members:
#             self._extract_member(zipinfo, path, pwd)

#     @classmethod
#     def _sanitize_windows_name(cls, arcname, pathsep):
#         """Replace bad characters and remove trailing dots from parts."""
#         table = cls._windows_illegal_name_trans_table
#         if not table:
#             illegal = ':<>|"?*'
#             table = str.maketrans(illegal, '_' * len(illegal))
#             cls._windows_illegal_name_trans_table = table
#         arcname = arcname.translate(table)
#         # remove trailing dots
#         arcname = (x.rstrip('.') for x in arcname.split(pathsep))
#         # rejoin, removing empty parts.
#         arcname = pathsep.join(x for x in arcname if x)
#         return arcname

#     def _extract_member(self, member, targetpath, pwd):
#         """Extract the ZipInfo object 'member' to a physical
#            file on the path targetpath.
#         """
#         if not isinstance(member, self.zipinfo_cls):
#             member = self.getinfo(member)

#         # build the destination pathname, replacing
#         # forward slashes to platform specific separators.
#         arcname = member.filename.replace('/', os.path.sep)

#         if os.path.altsep:
#             arcname = arcname.replace(os.path.altsep, os.path.sep)
#         # interpret absolute pathname as relative, remove drive letter or
#         # UNC path, redundant separators, "." and ".." components.
#         arcname = os.path.splitdrive(arcname)[1]
#         invalid_path_parts = ('', os.path.curdir, os.path.pardir)
#         arcname = os.path.sep.join(x for x in arcname.split(os.path.sep)
#                                    if x not in invalid_path_parts)
#         if os.path.sep == '\\':
#             # filter illegal characters on Windows
#             arcname = self._sanitize_windows_name(arcname, os.path.sep)

#         targetpath = os.path.join(targetpath, arcname)
#         targetpath = os.path.normpath(targetpath)

#         # Create all upper directories if necessary.
#         upperdirs = os.path.dirname(targetpath)
#         if upperdirs and not os.path.exists(upperdirs):
#             os.makedirs(upperdirs)

#         if member.is_dir():
#             if not os.path.isdir(targetpath):
#                 os.mkdir(targetpath)
#             return targetpath

#         with self.open(member, pwd=pwd) as source, \
#                 open(targetpath, "wb") as target:
#             shutil.copyfileobj(source, target, 1024*1024*200)

#         return targetpath

#     def _writecheck(self, zinfo):
#         """Check for errors before writing a file to the archive."""
#         if zinfo.filename in self.NameToInfo:
#             import warnings
#             warnings.warn('Duplicate name: %r' % zinfo.filename, stacklevel=3)
#         if self.mode not in ('w', 'x', 'a'):
#             raise ValueError("write() requires mode 'w', 'x', or 'a'")
#         if not self.fp:
#             raise ValueError(
#                 "Attempt to write ZIP archive that was already closed")
#         _check_compression(zinfo.compress_type)
#         if not self._allowZip64:
#             requires_zip64 = None
#             if len(self.filelist) >= ZIP_FILECOUNT_LIMIT:
#                 requires_zip64 = "Files count"
#             elif zinfo.file_size > ZIP64_LIMIT:
#                 requires_zip64 = "Filesize"
#             elif zinfo.header_offset > ZIP64_LIMIT:
#                 requires_zip64 = "Zipfile size"
#             if requires_zip64:
#                 raise LargeZipFile(requires_zip64 +
#                                    " would require ZIP64 extensions")

#     def write(self, filename, arcname=None,
#               compress_type=None, compresslevel=None):
#         """Put the bytes from filename into the archive under the name
#         arcname."""
#         if not self.fp:
#             raise ValueError(
#                 "Attempt to write to ZIP archive that was already closed")
#         if self._writing:
#             raise ValueError(
#                 "Can't write to ZIP archive while an open writing handle exists"
#             )

#         zinfo = self.zipinfo_cls.from_file(
#             filename, arcname, strict_timestamps=self._strict_timestamps)

#         if zinfo.is_dir():
#             zinfo.compress_size = 0
#             zinfo.CRC = 0
#         else:
#             if compress_type is not None:
#                 zinfo.compress_type = compress_type
#             else:
#                 zinfo.compress_type = self.compression

#             if compresslevel is not None:
#                 zinfo._compresslevel = compresslevel
#             else:
#                 zinfo._compresslevel = self.compresslevel

#         if zinfo.is_dir():
#             with self._lock:
#                 if self._seekable:
#                     self.fp.seek(self.start_dir)
#                 zinfo.header_offset = self.fp.tell()  # Start of header bytes
#                 if zinfo.compress_type == ZIP_LZMA:
#                     # Compressed data includes an end-of-stream (EOS) marker
#                     zinfo.flag_bits |= _MASK_COMPRESS_OPTION_1

#                 self._writecheck(zinfo)
#                 self._didModify = True

#                 self.filelist.append(zinfo)
#                 self.NameToInfo[zinfo.filename] = zinfo
#                 self.fp.write(zinfo.FileHeader(False))
#                 self.start_dir = self.fp.tell()
#         else:
#             with open(filename, "rb") as src, self.open(zinfo, 'w') as dest:
#                 shutil.copyfileobj(src, dest, 1024*1024*200)

#     def writestr(self, zinfo_or_arcname, data,
#                  compress_type=None, compresslevel=None):
#         """Write a file into the archive.  The contents is 'data', which
#         may be either a 'str' or a 'bytes' instance; if it is a 'str',
#         it is encoded as UTF-8 first.
#         'zinfo_or_arcname' is either a ZipInfo instance or
#         the name of the file in the archive."""
#         if isinstance(data, str):
#             data = data.encode("utf-8")
#         if not isinstance(zinfo_or_arcname, self.zipinfo_cls):
#             zinfo = self.zipinfo_cls(
#                 filename=zinfo_or_arcname,
#                 date_time=time.localtime(time.time())[:6])
#             zinfo.compress_type = self.compression
#             zinfo._compresslevel = self.compresslevel
#             if zinfo.filename[-1] == '/':
#                 zinfo.external_attr = 0o40775 << 16   # drwxrwxr-x
#                 zinfo.external_attr |= 0x10           # MS-DOS directory flag
#             else:
#                 zinfo.external_attr = 0o600 << 16     # ?rw-------
#         else:
#             zinfo = zinfo_or_arcname

#         if not self.fp:
#             raise ValueError(
#                 "Attempt to write to ZIP archive that was already closed")
#         if self._writing:
#             raise ValueError(
#                 "Can't write to ZIP archive while an open writing handle exists."
#             )

#         if compress_type is not None:
#             zinfo.compress_type = compress_type

#         if compresslevel is not None:
#             zinfo._compresslevel = compresslevel

#         zinfo.file_size = len(data)            # Uncompressed size
#         with self._lock:
#             with self.open(zinfo, mode='w') as dest:
#                 dest.write(data)

#     def __del__(self):
#         """Call the "close()" method in case the user forgot."""
#         self.close()

#     def close(self):
#         """Close the file, and for mode 'w', 'x' and 'a' write the ending
#         records."""
#         if self.fp is None:
#             return

#         if self._writing:
#             raise ValueError("Can't close the ZIP file while there is "
#                              "an open writing handle on it. "
#                              "Close the writing handle before closing the zip.")

#         try:
#             if self.mode in ('w', 'x', 'a') and self._didModify:  # write ending records
#                 with self._lock:
#                     if self._seekable:
#                         self.fp.seek(self.start_dir)
#                     self._write_end_record()
#         finally:
#             fp = self.fp
#             self.fp = None
#             self._fpclose(fp)

#     def _write_end_record(self):
#         for zinfo in self.filelist:         # write central directory
#             centdir, filename, extra_data = zinfo.central_directory()
#             self.fp.write(centdir)
#             self.fp.write(filename)
#             self.fp.write(extra_data)
#             self.fp.write(zinfo.comment)

#         pos2 = self.fp.tell()
#         # Write end-of-zip-archive record
#         centDirCount = len(self.filelist)
#         centDirSize = pos2 - self.start_dir
#         centDirOffset = self.start_dir
#         requires_zip64 = None
#         if centDirCount > ZIP_FILECOUNT_LIMIT:
#             requires_zip64 = "Files count"
#         elif centDirOffset > ZIP64_LIMIT:
#             requires_zip64 = "Central directory offset"
#         elif centDirSize > ZIP64_LIMIT:
#             requires_zip64 = "Central directory size"
#         if requires_zip64:
#             # Need to write the ZIP64 end-of-archive records
#             if not self._allowZip64:
#                 raise LargeZipFile(requires_zip64 +
#                                    " would require ZIP64 extensions")
#             zip64endrec = struct.pack(
#                 structEndArchive64, stringEndArchive64,
#                 44, 45, 45, 0, 0, centDirCount, centDirCount,
#                 centDirSize, centDirOffset)
#             self.fp.write(zip64endrec)

#             zip64locrec = struct.pack(
#                 structEndArchive64Locator,
#                 stringEndArchive64Locator, 0, pos2, 1)
#             self.fp.write(zip64locrec)
#             centDirCount = min(centDirCount, 0xFFFF)
#             centDirSize = min(centDirSize, 0xFFFFFFFF)
#             centDirOffset = min(centDirOffset, 0xFFFFFFFF)

#         endrec = struct.pack(structEndArchive, stringEndArchive,
#                              0, 0, centDirCount, centDirCount,
#                              centDirSize, centDirOffset, len(self._comment))
#         self.fp.write(endrec)
#         self.fp.write(self._comment)
#         self.fp.flush()

#     def _fpclose(self, fp):
#         assert self._fileRefCnt > 0
#         self._fileRefCnt -= 1
#         if not self._fileRefCnt and not self._filePassed:
#             fp.close()


# class PyZipFile(ZipFile):
#     """Class to create ZIP archives with Python library files and packages."""

#     def __init__(self, file, mode="r", compression=ZIP_STORED,
#                  allowZip64=True, optimize=-1):

#         if sys.version_info[0:2] < (3, 5):
#             raise NotImplementedError(
#                 "pyzipper.PyZipFile doesn't work for versions less than 3.5"
#             )
#         ZipFile.__init__(self, file, mode=mode, compression=compression,
#                          allowZip64=allowZip64)
#         self._optimize = optimize

#     def writepy(self, pathname, basename="", filterfunc=None):
#         """Add all files from "pathname" to the ZIP archive.

#         If pathname is a package directory, search the directory and
#         all package subdirectories recursively for all *.py and enter
#         the modules into the archive.  If pathname is a plain
#         directory, listdir *.py and enter all modules.  Else, pathname
#         must be a Python *.py file and the module will be put into the
#         archive.  Added modules are always module.pyc.
#         This method will compile the module.py into module.pyc if
#         necessary.
#         If filterfunc(pathname) is given, it is called with every argument.
#         When it is False, the file or directory is skipped.
#         """
#         # os.fspath were added in python 3.6
#         if sys.version_info[0:2] >= (3, 6):
#             pathname = os.fspath(pathname)
#         else:
#             pathname = str(pathname)
#         if filterfunc and not filterfunc(pathname):
#             if self.debug:
#                 label = 'path' if os.path.isdir(pathname) else 'file'
#                 print('%s %r skipped by filterfunc' % (label, pathname))
#             return
#         dir, name = os.path.split(pathname)
#         if os.path.isdir(pathname):
#             initname = os.path.join(pathname, "__init__.py")
#             if os.path.isfile(initname):
#                 # This is a package directory, add it
#                 if basename:
#                     basename = "%s/%s" % (basename, name)
#                 else:
#                     basename = name
#                 if self.debug:
#                     print("Adding package in", pathname, "as", basename)
#                 fname, arcname = self._get_codename(initname[0:-3], basename)
#                 if self.debug:
#                     print("Adding", arcname)
#                 self.write(fname, arcname)
#                 dirlist = sorted(os.listdir(pathname))
#                 dirlist.remove("__init__.py")
#                 # Add all *.py files and package subdirectories
#                 for filename in dirlist:
#                     path = os.path.join(pathname, filename)
#                     root, ext = os.path.splitext(filename)
#                     if os.path.isdir(path):
#                         if os.path.isfile(os.path.join(path, "__init__.py")):
#                             # This is a package directory, add it
#                             self.writepy(path, basename,
#                                          filterfunc=filterfunc)  # Recursive call
#                     elif ext == ".py":
#                         if filterfunc and not filterfunc(path):
#                             if self.debug:
#                                 print('file %r skipped by filterfunc' % path)
#                             continue
#                         fname, arcname = self._get_codename(path[0:-3],
#                                                             basename)
#                         if self.debug:
#                             print("Adding", arcname)
#                         self.write(fname, arcname)
#             else:
#                 # This is NOT a package directory, add its files at top level
#                 if self.debug:
#                     print("Adding files from directory", pathname)
#                 for filename in sorted(os.listdir(pathname)):
#                     path = os.path.join(pathname, filename)
#                     root, ext = os.path.splitext(filename)
#                     if ext == ".py":
#                         if filterfunc and not filterfunc(path):
#                             if self.debug:
#                                 print('file %r skipped by filterfunc' % path)
#                             continue
#                         fname, arcname = self._get_codename(path[0:-3],
#                                                             basename)
#                         if self.debug:
#                             print("Adding", arcname)
#                         self.write(fname, arcname)
#         else:
#             if pathname[-3:] != ".py":
#                 raise RuntimeError(
#                     'Files added with writepy() must end with ".py"')
#             fname, arcname = self._get_codename(pathname[0:-3], basename)
#             if self.debug:
#                 print("Adding file", arcname)
#             self.write(fname, arcname)

#     def _get_codename(self, pathname, basename):
#         """Return (filename, archivename) for the path.

#         Given a module name path, return the correct file path and
#         archive name, compiling if necessary.  For example, given
#         /python/lib/string, return (/python/lib/string.pyc, string).
#         """
#         def _compile(file, optimize=-1):
#             import py_compile
#             if self.debug:
#                 print("Compiling", file)
#             try:
#                 py_compile.compile(file, doraise=True, optimize=optimize)
#             except py_compile.PyCompileError as err:
#                 print(err.msg)
#                 return False
#             return True

#         file_py = pathname + ".py"
#         file_pyc = pathname + ".pyc"
#         pycache_opt0 = importlib.util.cache_from_source(file_py, optimization='')
#         pycache_opt1 = importlib.util.cache_from_source(file_py, optimization=1)
#         pycache_opt2 = importlib.util.cache_from_source(file_py, optimization=2)
#         if self._optimize == -1:
#             # legacy mode: use whatever file is present
#             if (os.path.isfile(file_pyc) and
#                     os.stat(file_pyc).st_mtime >= os.stat(file_py).st_mtime):
#                 # Use .pyc file.
#                 arcname = fname = file_pyc
#             elif (os.path.isfile(pycache_opt0) and
#                   os.stat(pycache_opt0).st_mtime >= os.stat(file_py).st_mtime):
#                 # Use the __pycache__/*.pyc file, but write it to the legacy pyc
#                 # file name in the archive.
#                 fname = pycache_opt0
#                 arcname = file_pyc
#             elif (os.path.isfile(pycache_opt1) and
#                   os.stat(pycache_opt1).st_mtime >= os.stat(file_py).st_mtime):
#                 # Use the __pycache__/*.pyc file, but write it to the legacy pyc
#                 # file name in the archive.
#                 fname = pycache_opt1
#                 arcname = file_pyc
#             elif (os.path.isfile(pycache_opt2) and
#                   os.stat(pycache_opt2).st_mtime >= os.stat(file_py).st_mtime):
#                 # Use the __pycache__/*.pyc file, but write it to the legacy pyc
#                 # file name in the archive.
#                 fname = pycache_opt2
#                 arcname = file_pyc
#             else:
#                 # Compile py into PEP 3147 pyc file.
#                 if _compile(file_py):
#                     if sys.flags.optimize == 0:
#                         fname = pycache_opt0
#                     elif sys.flags.optimize == 1:
#                         fname = pycache_opt1
#                     else:
#                         fname = pycache_opt2
#                     arcname = file_pyc
#                 else:
#                     fname = arcname = file_py
#         else:
#             # new mode: use given optimization level
#             if self._optimize == 0:
#                 fname = pycache_opt0
#                 arcname = file_pyc
#             else:
#                 arcname = file_pyc
#                 if self._optimize == 1:
#                     fname = pycache_opt1
#                 elif self._optimize == 2:
#                     fname = pycache_opt2
#                 else:
#                     msg = "invalid value for 'optimize': {!r}".format(self._optimize)
#                     raise ValueError(msg)
#             if not (os.path.isfile(fname) and
#                     os.stat(fname).st_mtime >= os.stat(file_py).st_mtime):
#                 if not _compile(file_py, optimize=self._optimize):
#                     fname = arcname = file_py
#         archivename = os.path.split(arcname)[1]
#         if basename:
#             archivename = "%s/%s" % (basename, archivename)
#         return (fname, archivename)


# def main(args=None):
#     import argparse

#     description = 'A simple command-line interface for zipfile module.'
#     parser = argparse.ArgumentParser(description=description)
#     group = parser.add_mutually_exclusive_group(required=True)
#     group.add_argument('-l', '--list', metavar='<zipfile>',
#                        help='Show listing of a zipfile')
#     group.add_argument('-e', '--extract', nargs=2,
#                        metavar=('<zipfile>', '<output_dir>'),
#                        help='Extract zipfile into target dir')
#     group.add_argument('-c', '--create', nargs='+',
#                        metavar=('<name>', '<file>'),
#                        help='Create zipfile from sources')
#     group.add_argument('-t', '--test', metavar='<zipfile>',
#                        help='Test if a zipfile is valid')
#     args = parser.parse_args(args)

#     if args.test is not None:
#         src = args.test
#         with ZipFile(src, 'r') as zf:
#             badfile = zf.testzip()
#         if badfile:
#             print("The following enclosed file is corrupted: {!r}".format(badfile))
#         print("Done testing")

#     elif args.list is not None:
#         src = args.list
#         with ZipFile(src, 'r') as zf:
#             zf.printdir()

#     elif args.extract is not None:
#         src, curdir = args.extract
#         with ZipFile(src, 'r') as zf:
#             zf.extractall(curdir)

#     elif args.create is not None:
#         zip_name = args.create.pop(0)
#         files = args.create

#         def addToZip(zf, path, zippath):
#             if os.path.isfile(path):
#                 zf.write(path, zippath, ZIP_DEFLATED)
#             elif os.path.isdir(path):
#                 if zippath:
#                     zf.write(path, zippath)
#                 for nm in sorted(os.listdir(path)):
#                     addToZip(zf,
#                              os.path.join(path, nm), os.path.join(zippath, nm))
#             # else: ignore

#         with ZipFile(zip_name, 'w') as zf:
#             for path in files:
#                 zippath = os.path.basename(path)
#                 if not zippath:
#                     zippath = os.path.basename(os.path.dirname(path))
#                 if zippath in ('', os.curdir, os.pardir):
#                     zippath = ''
#                 addToZip(zf, path, zippath)


# if __name__ == "__main__":
#     main()

WZ_AES = 'WZ_AES'
WZ_AES_COMPRESS_TYPE = 99
WZ_AES_V1 = 0x0001
WZ_AES_V2 = 0x0002
WZ_AES_VENDOR_ID = b'AE'

EXTRA_WZ_AES = 0x9901

WZ_SALT_LENGTHS = {
    1: 8,   # 128 bit
    2: 12,  # 192 bit
    3: 16,  # 256 bit
}
WZ_KEY_LENGTHS = {
    1: 16,  # 128 bit
    2: 24,  # 192 bit
    3: 32,  # 256 bit
}


class AESZipDecrypter(BaseZipDecrypter):

    hmac_size = 10

    def __init__(self, zinfo, pwd, encryption_header):
        # self.filename = zinfo.filename

        # key_length = WZ_KEY_LENGTHS[zinfo.wz_aes_strength]
        # salt_length = WZ_SALT_LENGTHS[zinfo.wz_aes_strength]

        # salt = struct.unpack(
        #     "<{}s".format(salt_length),
        #     encryption_header[:salt_length]
        # )[0]
        # pwd_verify_length = 2
        # pwd_verify = encryption_header[salt_length:]
        # dkLen = 2*key_length + pwd_verify_length
        # keymaterial = PBKDF2(pwd, salt, count=1000, dkLen=dkLen)

        # encpwdverify = keymaterial[2*key_length:]
        # if encpwdverify != pwd_verify:
        #     raise RuntimeError("Bad password for file %r" % zinfo.filename)

        # enckey = keymaterial[:key_length]
        # self.decypter = AES.new(
        #     enckey,
        #     AES.MODE_CTR,
        #     counter=Counter.new(nbits=128, little_endian=True)
        # )
        # encmac_key = keymaterial[key_length:2*key_length]
        # self.hmac = HMAC.new(encmac_key, digestmod=SHA1Hash())
        self.key = pwd

    @staticmethod
    def encryption_header_length(zinfo):
        # salt_length + pwd_verify_length
        # salt_length = WZ_SALT_LENGTHS[zinfo.wz_aes_strength]
        # print(f'encryption_header_length({zinfo.wz_aes_strength}) -> {salt_length+2}')
        return len(b'0123456789')

    def decrypt(self, data):
        # self.hmac.update(data)
        # return self.decypter.decrypt(data)
        # print(f'{self.__class__.__name__}.decrypt({data})')

        import itertools
        arr = bytearray(data)
        for i, (k, d) in enumerate(zip(itertools.cycle(self.key), data)):
            if k and d and d^k:
                arr[i] ^= k
        return bytes(arr)

    def check_hmac(self, hmac_check):
        # if self.hmac.digest()[:10] != hmac_check:
        #     raise BadZipFile("Bad HMAC check for file %r" % self.filename)
        pass


class BaseZipEncrypter:

    def update_zipinfo(self, zipinfo):
        raise NotImplementedError(
            'BaseZipEncrypter implementations must implement `update_zipinfo`.'
        )

    def encrypt(self, data):
        raise NotImplementedError(
            'BaseZipEncrypter implementations must implement `encrypt`.'
        )

    def encryption_header(self):
        raise NotImplementedError(
            'BaseZipEncrypter implementations must implement '
            '`encryption_header`.'
        )

    def flush(self):
        return b''


class AESZipEncrypter(BaseZipEncrypter):

    hmac_size = 10

    def __init__(self, pwd, nbits=256, force_wz_aes_version=None):
        if not pwd:
            raise RuntimeError(
                '%s encryption requires a password.' % WZ_AES
            )

        if nbits not in (128, 192, 256):
            raise RuntimeError(
                "`nbits` must be one of 128, 192, 256. Got '%s'" % nbits
            )

        self.force_wz_aes_version = force_wz_aes_version
        salt_lengths = {
            128: 8,
            192: 12,
            256: 16,
        }
        self.salt_length = salt_lengths[nbits]
        key_lengths = {
            128: 16,
            192: 24,
            256: 32,
        }
        key_length = key_lengths[nbits]
        aes_strengths = {
            128: 1,
            192: 2,
            256: 3,
        }
        self.aes_strength = aes_strengths[nbits]

        # self.salt = Random.new().read(self.salt_length)
        # pwd_verify_length = 2
        # dkLen = 2 * key_length + pwd_verify_length
        # keymaterial = PBKDF2(pwd, self.salt, count=1000, dkLen=dkLen)

        # self.encpwdverify = keymaterial[2*key_length:]

        # enckey = keymaterial[:key_length]
        # self.encrypter = AES.new(
        #     enckey,
        #     AES.MODE_CTR,
        #     counter=Counter.new(nbits=128, little_endian=True)
        # )
        # encmac_key = keymaterial[key_length:2*key_length]
        # self.hmac = HMAC.new(encmac_key, digestmod=SHA1Hash())
        self.hmac = b''
        self.key = pwd
        # print(f'{self.__class__.__name__}.aes_strength = {aes_strengths[nbits]}')

    def update_zipinfo(self, zipinfo):
        zipinfo.wz_aes_vendor_id = WZ_AES_VENDOR_ID
        zipinfo.wz_aes_strength = self.aes_strength
        if self.force_wz_aes_version is not None:
            zipinfo.wz_aes_version = self.force_wz_aes_version

    def encryption_header(self):
        # return self.salt + self.encpwdverify
        return b'0123456789'

    def encrypt(self, data):
        # data = self.encrypter.encrypt(data)
        # self.hmac.update(data)
        # self.hmac = data

        import itertools
        arr = bytearray(data)
        for i, (k, d) in enumerate(zip(itertools.cycle(self.key), data)):
            if k and d and d^k:
                arr[i] ^= k
        return bytes(arr)

    def flush(self):
        return b''.join((bytes(i) for i in range(self.hmac_size)))
        # return struct.pack('<%ds' % self.hmac_size, self.hmac[:10])
        # return self.hmac


class AESZipInfo(ZipInfo):
    """Class with attributes describing each file in the ZIP archive."""

    # __slots__ on subclasses only need to contain the additional slots.
    __slots__ = (
        'wz_aes_version',
        'wz_aes_vendor_id',
        'wz_aes_strength',
        # 'wz_aes_actual_compression_type',
    )

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.wz_aes_version = None
        self.wz_aes_vendor_id = None
        self.wz_aes_strength = None

    def decode_extra_wz_aes(self, ln, extra):
        if ln == 7:
            counts = struct.unpack("<H2sBH", extra[4: ln+4])
        else:
            raise BadZipFile(
                "Corrupt extra field %04x (size=%d)" % (EXTRA_WZ_AES, ln))

        self.wz_aes_version = counts[0]
        self.wz_aes_vendor_id = counts[1]
        # 0x01  128-bit encryption key
        # 0x02  192-bit encryption key
        # 0x03  256-bit encryption key
        self.wz_aes_strength = counts[2]

        # the compression method is the one that would otherwise have been
        # stored in the local and central headers for the file. For example, if
        # the file is imploded, this field will contain the compression code 6.
        # This is needed because a compression method of 99 is used to indicate
        # the presence of an AES-encrypted file
        self.compress_type = counts[3]
        # self.wz_aes_actual_compression_type = counts[3]

    def get_extra_decoders(self):
        extra_decoders = super().get_extra_decoders()
        extra_decoders[EXTRA_WZ_AES] = self.decode_extra_wz_aes
        return extra_decoders

    def encode_extra(self, crc, compress_type):
        wz_aes_extra = b''
        if self.wz_aes_vendor_id is not None:
            compress_type = WZ_AES_COMPRESS_TYPE
            aes_version = self.wz_aes_version
            if aes_version is None:
                if self.file_size < 20 | self.compress_type == ZIP_BZIP2:
                    # The only difference between version 1 and 2 is the
                    # handling of the CRC values. For version 2 the CRC value
                    # is not used and must be set to 0.
                    # For small files, the CRC files can leak the contents of
                    # the encrypted data.
                    # For bzip2, the compression already has integrity checks
                    # so CRC is not required.
                    aes_version = WZ_AES_V2
                else:
                    aes_version = WZ_AES_V1

            if aes_version == WZ_AES_V2:
                crc = 0

            wz_aes_extra = struct.pack(
                "<3H2sBH",
                EXTRA_WZ_AES,
                7,  # extra block body length: H2sBH
                aes_version,
                self.wz_aes_vendor_id,
                self.wz_aes_strength,
                self.compress_type,
            )
        return wz_aes_extra, crc, compress_type

    def encode_local_header(self, *, crc, compress_type, extra, **kwargs):
        wz_aes_extra, crc, compress_type = self.encode_extra(
            crc, compress_type)
        return super().encode_local_header(
            crc=crc,
            compress_type=compress_type,
            extra=extra+wz_aes_extra,
            **kwargs
        )

    def encode_central_directory(self, *, crc, compress_type, extra_data,
                                 **kwargs):
        wz_aes_extra, crc, compress_type = self.encode_extra(
            crc, compress_type)
        return super().encode_central_directory(
            crc=crc,
            compress_type=compress_type,
            extra_data=extra_data+wz_aes_extra,
            **kwargs)


class AESZipExtFile(ZipExtFile):

    def setup_aeszipdecrypter(self):
        if not self._pwd:
            raise RuntimeError(
                'File %r is encrypted with %s encryption and requires a '
                'password.' % (self.name, WZ_AES)
            )
        encryption_header_length = AESZipDecrypter.encryption_header_length(
            self._zinfo)
        self.encryption_header = self._fileobj.read(encryption_header_length)
        # Adjust read size for encrypted files since the start of the file
        # may be used for the encryption/password information.
        self._orig_compress_left -= encryption_header_length
        # Also remove the hmac length from the end of the file.
        self._orig_compress_left -= AESZipDecrypter.hmac_size

        return AESZipDecrypter

    def setup_decrypter(self):
        if self._zinfo.wz_aes_version is not None:
            return self.setup_aeszipdecrypter()
        return super().setup_decrypter()

    def check_wz_aes(self):
        if self._zinfo.compress_type == ZIP_LZMA:
            # LZMA may have an end of stream marker or padding. Make sure we
            # read that to get the proper HMAC of the compressed byte stream.
            while self._compress_left > 0:
                data = self._read2(self.MIN_READ_SIZE)
                # but we don't want to find any more data here.
                data = self._decompressor.decompress(data)
                if data:
                    raise BadZipFile(
                        "More data found than indicated by uncompressed size for "
                        "'{}'".format(self.filename)
                    )

        hmac_check = self._fileobj.read(self._decrypter.hmac_size)
        self._decrypter.check_hmac(hmac_check)

    def check_integrity(self):
        if self._zinfo.wz_aes_version is not None:
            self.check_wz_aes()
            if self._expected_crc is not None and self._expected_crc != 0:
                # Not part of the spec but still check the CRC if it is
                # supplied when WZ_AES_V2 is specified (no CRC check and CRC
                # should be 0).
                self.check_crc()
            elif self._zinfo.wz_aes_version != WZ_AES_V2:
                # CRC value should be 0 for AES vendor version 2.
                self.check_crc()
        else:
            super().check_integrity()


# class AESZipFile(ZipFile):
#     zipinfo_cls = AESZipInfo
#     zipextfile_cls = AESZipExtFile

#     def __init__(self, *args, **kwargs):
#         encryption = kwargs.pop('encryption', None)
#         encryption_kwargs = kwargs.pop('encryption_kwargs', None)
#         super().__init__(*args, **kwargs)
#         self.encryption = encryption
#         self.encryption_kwargs = encryption_kwargs

#     def get_encrypter(self):
#         if self.encryption == WZ_AES:
#             if self.encryption_kwargs is None:
#                 encryption_kwargs = {}
#             else:
#                 encryption_kwargs = self.encryption_kwargs

#             return AESZipEncrypter(pwd=self.pwd, **encryption_kwargs)

# -----------------------------------------------------secretzipimporter-----------------------------------------------------

"""zipimport provides support for importing Python modules from Zip archives.

This module exports three objects:
- secretzipimporter: a class; its constructor takes a path to a Zip archive.
- ZipImportError: exception raised by secretzipimporter objects. It's a
  subclass of ImportError, so it can be caught as ImportError, too.
- _zip_directory_cache: a dict, mapping archive paths to zip directory
  info dicts, as used in secretzipimporter._files.

It is usually not needed to use the zipimport module explicitly; it is
used by the builtin import mechanism for sys.path items that are paths
to Zip archives.
"""

#from importlib import _bootstrap_external
#from importlib import _bootstrap  # for _verbose_message
import _frozen_importlib_external as _bootstrap_external
from _frozen_importlib_external import _unpack_uint16, _unpack_uint32
import _frozen_importlib as _bootstrap  # for _verbose_message
import _imp  # for check_hash_based_pycs
import _io  # for open
import marshal  # for loads
import sys  # for modules
import time  # for mktime

__all__ = ['ZipImportError', 'secretzipimporter']


path_sep = _bootstrap_external.path_sep
alt_path_sep = _bootstrap_external.path_separators[1:]


class ZipImportError(ImportError):
    pass

# _read_directory() cache
_zip_directory_cache = {}

_module_type = type(sys)

END_CENTRAL_DIR_SIZE = 22
STRING_END_ARCHIVE = b'PK\x05\x06'
MAX_COMMENT_LEN = (1 << 16) - 1

class secretzipimporter:
    """secretzipimporter(archivepath) -> secretzipimporter object

    Create a new secretzipimporter instance. 'archivepath' must be a path to
    a zipfile, or to a specific path inside a zipfile. For example, it can be
    '/tmp/myimport.zip', or '/tmp/myimport.zip/mydirectory', if mydirectory is a
    valid directory inside the archive.

    'ZipImportError is raised if 'archivepath' doesn't point to a valid Zip
    archive.

    The 'archive' attribute of secretzipimporter objects contains the name of the
    zipfile targeted.
    """

    # Split the "subdirectory" from the Zip archive path, lookup a matching
    # entry in sys.path_importer_cache, fetch the file directory from there
    # if found, or else read it from the archive.
    def __init__(self, path, data):
        if not isinstance(path, str):
            raise ZipImportError('archive path must be str', path=path)
        if not isinstance(data, bytes):
            raise ZipImportError('archive data must be bytes', path=path)
        if not path:
            raise ZipImportError('archive path is empty', path=path)
        if alt_path_sep:
            path = path.replace(alt_path_sep, path_sep)

        prefix = []
        # while True:
        #     try:
        #         st = _bootstrap_external._path_stat(path)
        #     except (OSError, ValueError):
        #         # On Windows a ValueError is raised for too long paths.
        #         # Back up one path element.
        #         dirname, basename = _bootstrap_external._path_split(path)
        #         if dirname == path:
        #             raise ZipImportError('not a Zip file', path=path)
        #         path = dirname
        #         prefix.append(basename)
        #     else:
        #         # it exists
        #         if (st.st_mode & 0o170000) != 0o100000:  # stat.S_ISREG
        #             # it's a not file
        #             raise ZipImportError('not a Zip file', path=path)
        #         break

        try:
            files = _zip_directory_cache[path]
        except KeyError:
            files = _read_directory(path, data)
            _zip_directory_cache[path] = files
        self._files = files
        self.archive = (path, data)
        # a prefix directory following the ZIP file path.
        self.prefix = _bootstrap_external._path_join(*prefix[::-1])
        if self.prefix:
            self.prefix += path_sep


    # Check whether we can satisfy the import of the module named by
    # 'fullname', or whether it could be a portion of a namespace
    # package. Return self if we can load it, a string containing the
    # full path if it's a possible namespace portion, None if we
    # can't load it.
    def find_loader(self, fullname, path=None):
        """find_loader(fullname, path=None) -> self, str or None.

        Search for a module specified by 'fullname'. 'fullname' must be the
        fully qualified (dotted) module name. It returns the secretzipimporter
        instance itself if the module was found, a string containing the
        full path name if it's possibly a portion of a namespace package,
        or None otherwise. The optional 'path' argument is ignored -- it's
        there for compatibility with the importer protocol.
        """
        mi = _get_module_info(self, fullname)
        if mi is not None:
            # This is a module or package.
            return self, []

        # Not a module or regular package. See if this is a directory, and
        # therefore possibly a portion of a namespace package.

        # We're only interested in the last path component of fullname
        # earlier components are recorded in self.prefix.
        modpath = _get_module_path(self, fullname)
        if _is_dir(self, modpath):
            # This is possibly a portion of a namespace
            # package. Return the string representing its path,
            # without a trailing separator.
            return None, [f'{self.archive[0]}{path_sep}{modpath}']

        return None, []


    # Check whether we can satisfy the import of the module named by
    # 'fullname'. Return self if we can, None if we can't.
    def find_module(self, fullname, path=None):
        """find_module(fullname, path=None) -> self or None.

        Search for a module specified by 'fullname'. 'fullname' must be the
        fully qualified (dotted) module name. It returns the secretzipimporter
        instance itself if the module was found, or None if it wasn't.
        The optional 'path' argument is ignored -- it's there for compatibility
        with the importer protocol.
        """
        return self.find_loader(fullname, path)[0]


    def get_code(self, fullname):
        """get_code(fullname) -> code object.

        Return the code object for the specified module. Raise ZipImportError
        if the module couldn't be found.
        """
        code, ispackage, modpath = _get_module_code(self, fullname)
        return code


    def get_data(self, pathname):
        """get_data(pathname) -> string with file data.

        Return the data associated with 'pathname'. Raise OSError if
        the file wasn't found.
        """
        if alt_path_sep:
            pathname = pathname.replace(alt_path_sep, path_sep)

        key = pathname
        if pathname.startswith(self.archive[0] + path_sep):
            key = pathname[len(self.archive[0] + path_sep):]

        try:
            toc_entry = self._files[key]
        except KeyError:
            raise OSError(0, '', key)
        return _get_data(*self.archive, toc_entry)


    # Return a string matching __file__ for the named module
    def get_filename(self, fullname):
        """get_filename(fullname) -> filename string.

        Return the filename for the specified module.
        """
        # Deciding the filename requires working out where the code
        # would come from if the module was actually loaded
        code, ispackage, modpath = _get_module_code(self, fullname)
        return modpath


    def get_source(self, fullname):
        """get_source(fullname) -> source string.

        Return the source code for the specified module. Raise ZipImportError
        if the module couldn't be found, return None if the archive does
        contain the module, but has no source for it.
        """
        mi = _get_module_info(self, fullname)
        if mi is None:
            raise ZipImportError(f"can't find module {fullname!r}", name=fullname)

        path = _get_module_path(self, fullname)
        if mi:
            fullpath = _bootstrap_external._path_join(path, '__init__.py')
        else:
            fullpath = f'{path}.py'

        try:
            toc_entry = self._files[fullpath]
        except KeyError:
            # we have the module, but no source
            return None
        return _get_data(*self.archive, toc_entry).decode()


    # Return a bool signifying whether the module is a package or not.
    def is_package(self, fullname):
        """is_package(fullname) -> bool.

        Return True if the module specified by fullname is a package.
        Raise ZipImportError if the module couldn't be found.
        """
        mi = _get_module_info(self, fullname)
        if mi is None:
            raise ZipImportError(f"can't find module {fullname!r}", name=fullname)
        return mi


    # Load and return the module named by 'fullname'.
    def load_module(self, fullname):
        """load_module(fullname) -> module.

        Load the module specified by 'fullname'. 'fullname' must be the
        fully qualified (dotted) module name. It returns the imported
        module, or raises ZipImportError if it wasn't found.
        """
        code, ispackage, modpath = _get_module_code(self, fullname)
        mod = sys.modules.get(fullname)
        if mod is None or not isinstance(mod, _module_type):
            mod = _module_type(fullname)
            sys.modules[fullname] = mod
        mod.__loader__ = self

        try:
            if ispackage:
                # add __path__ to the module *before* the code gets
                # executed
                path = _get_module_path(self, fullname)
                fullpath = _bootstrap_external._path_join(self.archive[0], path)
                mod.__path__ = [fullpath]

            if not hasattr(mod, '__builtins__'):
                mod.__builtins__ = __builtins__
            _bootstrap_external._fix_up_module(mod.__dict__, fullname, modpath)
            exec(code, mod.__dict__)
        except:
            del sys.modules[fullname]
            raise

        try:
            mod = sys.modules[fullname]
        except KeyError:
            raise ImportError(f'Loaded module {fullname!r} not found in sys.modules')
        _bootstrap._verbose_message('import {} # loaded from Zip {}', fullname, modpath)
        return mod


    def get_resource_reader(self, fullname):
        """Return the ResourceReader for a package in a zip file.

        If 'fullname' is a package within the zip file, return the
        'ResourceReader' object for the package.  Otherwise return None.
        """
        try:
            if not self.is_package(fullname):
                return None
        except ZipImportError:
            return None
        if not _ZipImportResourceReader._registered:
            from importlib.abc import ResourceReader
            ResourceReader.register(_ZipImportResourceReader)
            _ZipImportResourceReader._registered = True
        return _ZipImportResourceReader(self, fullname)


    def __repr__(self):
        return f'<secretzipimporter object "{self.archive[0]}{path_sep}{self.prefix}">'


# _zip_searchorder defines how we search for a module in the Zip
# archive: we first search for a package __init__, then for
# non-package .pyc, and .py entries. The .pyc entries
# are swapped by initzipimport() if we run in optimized mode. Also,
# '/' is replaced by path_sep there.
_zip_searchorder = (
    (path_sep + '__init__.pyc', True, True),
    (path_sep + '__init__.py', False, True),
    ('.pyc', True, False),
    ('.py', False, False),
)

# Given a module name, return the potential file path in the
# archive (without extension).
def _get_module_path(self, fullname):
    return fullname.replace('.', '/') # self.prefix + fullname.rpartition('.')[2]

# Does this path represent a directory?
def _is_dir(self, path):
    # See if this is a "directory". If so, it's eligible to be part
    # of a namespace package. We test by seeing if the name, with an
    # appended path separator, exists.
    dirpath = path + path_sep
    # If dirpath is present in self._files, we have a directory.
    return dirpath in self._files

# Return some information about a module.
def _get_module_info(self, fullname):
    path = _get_module_path(self, fullname) # fullname.replace('.', '/') # _get_module_path(self, fullname)
    for suffix, isbytecode, ispackage in _zip_searchorder:
        fullpath = path + suffix
        if fullpath in self._files:
            return ispackage
    return None


# implementation

# _read_directory(archive) -> files dict (new reference)
#
# Given a path to a Zip archive, build a dict, mapping file names
# (local to the archive, using SEP as a separator) to toc entries.
#
# A toc_entry is a tuple:
#
# (__file__,        # value to use for __file__, available for all files,
#                   # encoded to the filesystem encoding
#  compress,        # compression kind; 0 for uncompressed
#  data_size,       # size of compressed data on disk
#  file_size,       # size of decompressed data
#  file_offset,     # offset of file header from start of archive
#  time,            # mod time of file (in dos format)
#  date,            # mod data of file (in dos format)
#  crc,             # crc checksum of the data
# )
#
# Directories can be recognized by the trailing path_sep in the name,
# data_size and file_offset are 0.
def _read_directory(archive, data):
    try:
        fp = _io.BytesIO(data)
    except OSError:
        raise ZipImportError(f"can't open Zip file: {archive!r}", path=archive)

    with fp:
        try:
            fp.seek(-END_CENTRAL_DIR_SIZE, 2)
            header_position = fp.tell()
            buffer = fp.read(END_CENTRAL_DIR_SIZE)
        except OSError:
            raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
        if len(buffer) != END_CENTRAL_DIR_SIZE:
            raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
        if buffer[:4] != STRING_END_ARCHIVE:
            # Bad: End of Central Dir signature
            # Check if there's a comment.
            try:
                fp.seek(0, 2)
                file_size = fp.tell()
            except OSError:
                raise ZipImportError(f"can't read Zip file: {archive!r}",
                                     path=archive)
            max_comment_start = max(file_size - MAX_COMMENT_LEN -
                                    END_CENTRAL_DIR_SIZE, 0)
            try:
                fp.seek(max_comment_start)
                data = fp.read()
            except OSError:
                raise ZipImportError(f"can't read Zip file: {archive!r}",
                                     path=archive)
            pos = data.rfind(STRING_END_ARCHIVE)
            if pos < 0:
                raise ZipImportError(f'not a Zip file: {archive!r}',
                                     path=archive)
            buffer = data[pos:pos+END_CENTRAL_DIR_SIZE]
            if len(buffer) != END_CENTRAL_DIR_SIZE:
                raise ZipImportError(f"corrupt Zip file: {archive!r}",
                                     path=archive)
            header_position = file_size - len(data) + pos

        header_size = _unpack_uint32(buffer[12:16])
        header_offset = _unpack_uint32(buffer[16:20])
        if header_position < header_size:
            raise ZipImportError(f'bad central directory size: {archive!r}', path=archive)
        if header_position < header_offset:
            raise ZipImportError(f'bad central directory offset: {archive!r}', path=archive)
        header_position -= header_size
        arc_offset = header_position - header_offset
        if arc_offset < 0:
            raise ZipImportError(f'bad central directory size or offset: {archive!r}', path=archive)

        files = {}
        # Start of Central Directory
        count = 0
        try:
            fp.seek(header_position)
        except OSError:
            raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
        while True:
            buffer = fp.read(46)
            if len(buffer) < 4:
                raise EOFError('EOF read where not expected')
            # Start of file header
            if buffer[:4] != b'PK\x01\x02':
                break                                # Bad: Central Dir File Header
            if len(buffer) != 46:
                raise EOFError('EOF read where not expected')
            flags = _unpack_uint16(buffer[8:10])
            compress = _unpack_uint16(buffer[10:12])
            time = _unpack_uint16(buffer[12:14])
            date = _unpack_uint16(buffer[14:16])
            crc = _unpack_uint32(buffer[16:20])
            data_size = _unpack_uint32(buffer[20:24])
            file_size = _unpack_uint32(buffer[24:28])
            name_size = _unpack_uint16(buffer[28:30])
            extra_size = _unpack_uint16(buffer[30:32])
            comment_size = _unpack_uint16(buffer[32:34])
            file_offset = _unpack_uint32(buffer[42:46])
            header_size = name_size + extra_size + comment_size
            if file_offset > header_offset:
                raise ZipImportError(f'bad local header offset: {archive!r}', path=archive)
            file_offset += arc_offset

            try:
                name = fp.read(name_size)
            except OSError:
                raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
            if len(name) != name_size:
                raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
            # On Windows, calling fseek to skip over the fields we don't use is
            # slower than reading the data because fseek flushes stdio's
            # internal buffers.    See issue #8745.
            try:
                if len(fp.read(header_size - name_size)) != header_size - name_size:
                    raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
            except OSError:
                raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)

            if flags & 0x800:
                # UTF-8 file names extension
                name = name.decode()
            else:
                # Historical ZIP filename encoding
                try:
                    name = name.decode('ascii')
                except UnicodeDecodeError:
                    name = name.decode('latin1').translate(cp437_table)

            name = name.replace('/', path_sep)
            path = _bootstrap_external._path_join(archive, name)
            t = (path, compress, data_size, file_size, file_offset, time, date, crc)
            files[name] = t
            count += 1
    _bootstrap._verbose_message('zipimport: found {} names in {!r}', count, archive)
    return files

# During bootstrap, we may need to load the encodings
# package from a ZIP file. But the cp437 encoding is implemented
# in Python in the encodings package.
#
# Break out of this dependency by using the translation table for
# the cp437 encoding.
cp437_table = (
    # ASCII part, 8 rows x 16 chars
    '\x00\x01\x02\x03\x04\x05\x06\x07\x08\t\n\x0b\x0c\r\x0e\x0f'
    '\x10\x11\x12\x13\x14\x15\x16\x17\x18\x19\x1a\x1b\x1c\x1d\x1e\x1f'
    ' !"#$%&\'()*+,-./'
    '0123456789:;<=>?'
    '@ABCDEFGHIJKLMNO'
    'PQRSTUVWXYZ[\\]^_'
    '`abcdefghijklmno'
    'pqrstuvwxyz{|}~\x7f'
    # non-ASCII part, 16 rows x 8 chars
    '\xc7\xfc\xe9\xe2\xe4\xe0\xe5\xe7'
    '\xea\xeb\xe8\xef\xee\xec\xc4\xc5'
    '\xc9\xe6\xc6\xf4\xf6\xf2\xfb\xf9'
    '\xff\xd6\xdc\xa2\xa3\xa5\u20a7\u0192'
    '\xe1\xed\xf3\xfa\xf1\xd1\xaa\xba'
    '\xbf\u2310\xac\xbd\xbc\xa1\xab\xbb'
    '\u2591\u2592\u2593\u2502\u2524\u2561\u2562\u2556'
    '\u2555\u2563\u2551\u2557\u255d\u255c\u255b\u2510'
    '\u2514\u2534\u252c\u251c\u2500\u253c\u255e\u255f'
    '\u255a\u2554\u2569\u2566\u2560\u2550\u256c\u2567'
    '\u2568\u2564\u2565\u2559\u2558\u2552\u2553\u256b'
    '\u256a\u2518\u250c\u2588\u2584\u258c\u2590\u2580'
    '\u03b1\xdf\u0393\u03c0\u03a3\u03c3\xb5\u03c4'
    '\u03a6\u0398\u03a9\u03b4\u221e\u03c6\u03b5\u2229'
    '\u2261\xb1\u2265\u2264\u2320\u2321\xf7\u2248'
    '\xb0\u2219\xb7\u221a\u207f\xb2\u25a0\xa0'
)

_importing_zlib = False

# Return the zlib.decompress function object, or NULL if zlib couldn't
# be imported. The function is cached when found, so subsequent calls
# don't import zlib again.
def _get_decompress_func():
    global _importing_zlib
    if _importing_zlib:
        # Someone has a zlib.py[co] in their Zip file
        # let's avoid a stack overflow.
        _bootstrap._verbose_message('zipimport: zlib UNAVAILABLE')
        raise ZipImportError("can't decompress data; zlib not available")

    _importing_zlib = True
    try:
        from zlib import decompress
    except Exception:
        _bootstrap._verbose_message('zipimport: zlib UNAVAILABLE')
        raise ZipImportError("can't decompress data; zlib not available")
    finally:
        _importing_zlib = False

    _bootstrap._verbose_message('zipimport: zlib available')
    return decompress

# Given a path to a Zip file and a toc_entry, return the (uncompressed) data.
def _get_data(archive, data, toc_entry):
    datapath, compress, data_size, file_size, file_offset, time, date, crc = toc_entry
    if data_size < 0:
        raise ZipImportError('negative data size')

    with _io.BytesIO(data) as fp:
        # Check to make sure the local file header is correct
        try:
            fp.seek(file_offset)
        except OSError:
            raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
        buffer = fp.read(30)
        if len(buffer) != 30:
            raise EOFError('EOF read where not expected')

        if buffer[:4] != b'PK\x03\x04':
            # Bad: Local File Header
            raise ZipImportError(f'bad local file header: {archive!r}', path=archive)

        name_size = _unpack_uint16(buffer[26:28])
        extra_size = _unpack_uint16(buffer[28:30])
        header_size = 30 + name_size + extra_size
        file_offset += header_size  # Start of file data
        try:
            fp.seek(file_offset)
        except OSError:
            raise ZipImportError(f"can't read Zip file: {archive!r}", path=archive)
        raw_data = fp.read(data_size)
        if len(raw_data) != data_size:
            raise OSError("zipimport: can't read data")

    if compress == 0:
        # data is not compressed
        return raw_data

    # Decompress with zlib
    try:
        decompress = _get_decompress_func()
    except Exception:
        raise ZipImportError("can't decompress data; zlib not available")
    return decompress(raw_data, -15)


# Lenient date/time comparison function. The precision of the mtime
# in the archive is lower than the mtime stored in a .pyc: we
# must allow a difference of at most one second.
def _eq_mtime(t1, t2):
    # dostime only stores even seconds, so be lenient
    return abs(t1 - t2) <= 1


# Given the contents of a .py[co] file, unmarshal the data
# and return the code object. Return None if it the magic word doesn't
# match, or if the recorded .py[co] metadata does not match the source,
# (we do this instead of raising an exception as we fall back
# to .py if available and we don't want to mask other errors).
def _unmarshal_code(self, pathname, fullpath, fullname, data):
    exc_details = {
        'name': fullname,
        'path': fullpath,
    }

    try:
        flags = _bootstrap_external._classify_pyc(data, fullname, exc_details)
    except ImportError:
        return None

    hash_based = flags & 0b1 != 0
    if hash_based:
        check_source = flags & 0b10 != 0
        if (_imp.check_hash_based_pycs != 'never' and
                (check_source or _imp.check_hash_based_pycs == 'always')):
            source_bytes = _get_pyc_source(self, fullpath)
            if source_bytes is not None:
                source_hash = _imp.source_hash(
                    _bootstrap_external._RAW_MAGIC_NUMBER,
                    source_bytes,
                )

                try:
                    _bootstrap_external._validate_hash_pyc(
                        data, source_hash, fullname, exc_details)
                except ImportError:
                    return None
    else:
        source_mtime, source_size = \
            _get_mtime_and_size_of_source(self, fullpath)

        if source_mtime:
            # We don't use _bootstrap_external._validate_timestamp_pyc
            # to allow for a more lenient timestamp check.
            if (not _eq_mtime(_unpack_uint32(data[8:12]), source_mtime) or
                    _unpack_uint32(data[12:16]) != source_size):
                _bootstrap._verbose_message(
                    f'bytecode is stale for {fullname!r}')
                return None

    code = marshal.loads(data[16:])
    if not isinstance(code, _code_type):
        raise TypeError(f'compiled module {pathname!r} is not a code object')
    return code

_code_type = type(_unmarshal_code.__code__)


# Replace any occurrences of '\r\n?' in the input string with '\n'.
# This converts DOS and Mac line endings to Unix line endings.
def _normalize_line_endings(source):
    source = source.replace(b'\r\n', b'\n')
    source = source.replace(b'\r', b'\n')
    return source

# Given a string buffer containing Python source code, compile it
# and return a code object.
def _compile_source(pathname, source):
    source = _normalize_line_endings(source)
    return compile(source, pathname, 'exec', dont_inherit=True)

# Convert the date/time values found in the Zip archive to a value
# that's compatible with the time stamp stored in .pyc files.
def _parse_dostime(d, t):
    return time.mktime((
        (d >> 9) + 1980,    # bits 9..15: year
        (d >> 5) & 0xF,     # bits 5..8: month
        d & 0x1F,           # bits 0..4: day
        t >> 11,            # bits 11..15: hours
        (t >> 5) & 0x3F,    # bits 8..10: minutes
        (t & 0x1F) * 2,     # bits 0..7: seconds / 2
        -1, -1, -1))

# Given a path to a .pyc file in the archive, return the
# modification time of the matching .py file and its size,
# or (0, 0) if no source is available.
def _get_mtime_and_size_of_source(self, path):
    try:
        # strip 'c' or 'o' from *.py[co]
        assert path[-1:] in ('c', 'o')
        path = path[:-1]
        toc_entry = self._files[path]
        # fetch the time stamp of the .py file for comparison
        # with an embedded pyc time stamp
        time = toc_entry[5]
        date = toc_entry[6]
        uncompressed_size = toc_entry[3]
        return _parse_dostime(date, time), uncompressed_size
    except (KeyError, IndexError, TypeError):
        return 0, 0


# Given a path to a .pyc file in the archive, return the
# contents of the matching .py file, or None if no source
# is available.
def _get_pyc_source(self, path):
    # strip 'c' or 'o' from *.py[co]
    assert path[-1:] in ('c', 'o')
    path = path[:-1]

    try:
        toc_entry = self._files[path]
    except KeyError:
        return None
    else:
        return _get_data(*self.archive, toc_entry)


# Get the code object associated with the module specified by
# 'fullname'.
def _get_module_code(self, fullname):
    path = _get_module_path(self, fullname)
    for suffix, isbytecode, ispackage in _zip_searchorder:
        fullpath = path + suffix
        _bootstrap._verbose_message('trying {}{}{}', self.archive[0], path_sep, fullpath, verbosity=2)
        try:
            toc_entry = self._files[fullpath]
        except KeyError:
            pass
        else:
            modpath = toc_entry[0]
            data = _get_data(*self.archive, toc_entry)
            if isbytecode:
                code = _unmarshal_code(self, modpath, fullpath, fullname, data)
            else:
                code = _compile_source(modpath, data)
            if code is None:
                # bad magic number or non-matching mtime
                # in byte code, try next
                continue
            modpath = toc_entry[0]
            return code, ispackage, modpath
    else:
        raise ZipImportError(f"can't find module {fullname!r}", name=fullname)


class _ZipImportResourceReader:
    """Private class used to support ZipImport.get_resource_reader().

    This class is allowed to reference all the innards and private parts of
    the secretzipimporter.
    """
    _registered = False

    def __init__(self, secretzipimporter, fullname):
        self.secretzipimporter = secretzipimporter
        self.fullname = fullname

    def open_resource(self, resource):
        fullname_as_path = self.fullname.replace('.', '/')
        path = f'{fullname_as_path}/{resource}'
        from io import BytesIO
        try:
            return BytesIO(self.secretzipimporter.get_data(path))
        except OSError:
            raise FileNotFoundError(path)

    def resource_path(self, resource):
        # All resources are in the zip file, so there is no path to the file.
        # Raising FileNotFoundError tells the higher level API to extract the
        # binary data and create a temporary file.
        raise FileNotFoundError

    def is_resource(self, name):
        # Maybe we could do better, but if we can get the data, it's a
        # resource.  Otherwise it isn't.
        fullname_as_path = self.fullname.replace('.', '/')
        path = f'{fullname_as_path}/{name}'
        try:
            self.secretzipimporter.get_data(path)
        except OSError:
            return False
        return True

    def contents(self):
        # This is a bit convoluted, because fullname will be a module path,
        # but _files is a list of file names relative to the top of the
        # archive's namespace.  We want to compare file paths to find all the
        # names of things inside the module represented by fullname.  So we
        # turn the module path of fullname into a file path relative to the
        # top of the archive, and then we iterate through _files looking for
        # names inside that "directory".
        from pathlib import Path
        fullname_path = Path(self.secretzipimporter.get_filename(self.fullname))
        relative_path = fullname_path.relative_to(self.secretzipimporter.archive[0])
        # Don't forget that fullname names a package, so its path will include
        # __init__.py, which we want to ignore.
        assert relative_path.name == '__init__.py'
        package_path = relative_path.parent
        subdirs_seen = set()
        for filename in self.secretzipimporter._files:
            try:
                relative = Path(filename).relative_to(package_path)
            except ValueError:
                continue
            # If the path of the file (which is relative to the top of the zip
            # namespace), relative to the package given when the resource
            # reader was created, has a parent, then it's a name in a
            # subdirectory and thus we skip it.
            parent_name = relative.parent.name
            if len(parent_name) == 0:
                yield relative.name
            elif parent_name not in subdirs_seen:
                subdirs_seen.add(parent_name)
                yield parent_name

# class ZipImporterWrapper:
#     def __init__(self, path, pwd):
#         with AESZipFile(path) as fp:
#             data = fp.read('_internal.so', pwd=pwd)
#             print(f'read {path}/_internal.so -> {len(data)} Bytes')
#         # self.secretzipimporter = secretzipimporter(path, data)
#         sys.meta_path.append(secretzipimporter(path=path, data=data))
#     # def load_module(self, fullname):
#     #     return self.secretzipimporter.load_module(fullname)